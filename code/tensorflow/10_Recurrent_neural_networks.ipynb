{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Recurrent neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load_series(filename ,series_dix=1):\n",
    "    try:\n",
    "        with open(filename) as csvfile:\n",
    "            csvreader = csv.reader(csvfile)\n",
    "            data = [float(row[series_dix]) for row in csvreader if len(row) > 0]\n",
    "            normalized_data = (data - np.mean(data)) / np.std(data)\n",
    "        return normalized_data\n",
    "    except IOError:\n",
    "        return None\n",
    "\n",
    "def split_data(data, percent_train=0.80):\n",
    "    num_rows = len(data)\n",
    "    train_data, test_data = [], []\n",
    "    for idx, row in enumerate(data):\n",
    "        if idx < num_rows * percent_train:\n",
    "            train_data.append(row)\n",
    "        else:\n",
    "            test_data.append(row)\n",
    "    return train_data, test_data\n",
    "\n",
    "def plot_results(train_x, predictions, actual, filename):\n",
    "    plt.figure()\n",
    "    num_train = len(train_x)\n",
    "    plt.plot(list(range(num_train)), train_x, color='b', label='training data')\n",
    "    plt.plot(list(range(num_train, num_train + len(predictions))), predictions, color='r', label='predicted')\n",
    "    plt.plot(list(range(num_train, num_train + len(actual))), actual, color='g', label='test data')\n",
    "    plt.legend()\n",
    "    \n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "class SeriesPredictor:\n",
    "    \n",
    "    def __init__(self, input_dim, seq_size, hidden_dim=10):\n",
    "        self.input_dim = input_dim\n",
    "        self.seq_size = seq_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.W_out = tf.Variable(tf.random_normal([hidden_dim, 1]), name='W_out')\n",
    "        self.b_out = tf.Variable(tf.random_normal([1]), name='b_out')\n",
    "        self.x = tf.placeholder(tf.float32, [None, seq_size, input_dim])\n",
    "        self.y = tf.placeholder(tf.float32, [None, seq_size])\n",
    "        self.cost = tf.reduce_mean(tf.square(self.model() - self.y))\n",
    "        self.train_op = tf.train.AdamOptimizer().minimize(self.cost)\n",
    "        self.saver = tf.train.Saver()\n",
    "        state_init = tf.Variable(tf.zeros([1, 5]))\n",
    "        self.init_state = tf.tile(state_init, [110, 1])\n",
    "        \n",
    "    def model(self):\n",
    "        cell = rnn.BasicLSTMCell(self.hidden_dim, reuse=tf.get_variable_scope().reuse, state_is_tuple=True)\n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, self.x, initial_state =self.init_state, dtype=tf.float32)\n",
    " #       outputs, states = tf.nn.dynamic_rnn(cell, self.x, dtype=tf.float32)\n",
    "        print(states)    \n",
    "        num_examples = tf.shape(self.x)[0]\n",
    "        W_repeated = tf.tile(tf.expand_dims(self.W_out, 0), [num_examples, 1, 1])\n",
    "        out = tf.matmul(outputs, W_repeated) + self.b_out\n",
    "        out = tf.squeeze(out)\n",
    "        print(out)\n",
    "        return out\n",
    "        \n",
    "    def train(self, train_x, train_y, test_x, test_y):\n",
    "        with tf.Session() as sess:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            max_patience = 3\n",
    "            patience = max_patience\n",
    "            min_test_err = float('inf')\n",
    "            step = 0\n",
    "            while patience > 0:\n",
    "                _, train_err = sess.run([self.train_op, self.cost], feed_dict={self.x: train_x, self.y: train_y})\n",
    "                if step % 100 == 0:\n",
    "                    test_err = sess.run(self.cost, feed_dict={self.x: test_x, self.y: test_y})\n",
    "                    print('step: {}\\t\\ttrain err: {}\\t\\ttest err: {}'.format(step, train_err, test_err))\n",
    "                    if test_err < min_test_err:\n",
    "                        min_test_err = test_err\n",
    "                        patience = max_patience\n",
    "                    else:\n",
    "                        patience -= 1\n",
    "                step += 1\n",
    "            save_path = self.saver.save(sess, \"model.ckpt\")\n",
    "            print(\"Model saved to {}\".format(save_path))\n",
    "        \n",
    "    def test(self, sess, test_x):\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        self.saver.restore(sess, \"./model.ckpt\")\n",
    "        output = sess.run(self.model(), feed_dict={self.x: test_x})\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "SeriesPredictor instance has no attribute 'init_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3114ce8344b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseq_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeriesPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'international-airline-passengers.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-3e1c442e84e4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, seq_size, hidden_dim)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-3e1c442e84e4>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasicLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_is_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m  \u001b[0;31m#       outputs, states = tf.nn.dynamic_rnn(cell, self.x, dtype=tf.float32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: SeriesPredictor instance has no attribute 'init_state'"
     ]
    }
   ],
   "source": [
    "seq_size = 5\n",
    "predictor = SeriesPredictor(input_dim=1, seq_size=seq_size, hidden_dim = 100)\n",
    "\n",
    "data = load_series('international-airline-passengers.csv')\n",
    "train_data, actual_vals = split_data(data)\n",
    "train_x, train_y = [], []\n",
    "for i in range(len(train_data) - seq_size - 1):\n",
    "    train_x.append(np.expand_dims(train_data[i:i+seq_size], axis=1).tolist())\n",
    "    train_y.append(train_data[i+1:i+seq_size+1])\n",
    "    \n",
    "test_x, test_y = [], []\n",
    "for i in range(len(actual_vals) - seq_size - 1):\n",
    "    test_x.append(np.expand_dims(actual_vals[i:i+seq_size], axis=1).tolist())\n",
    "    test_y.append(actual_vals[i+1:i+seq_size+1])\n",
    "\n",
    "predictor.train(train_x, train_y, test_x, test_y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  #  predicted_vals = predictor.test(sess, test_x)[:,0]\n",
    "  #  print('predicted_vals', np.shape(predicted_vals))\n",
    "  #  plot_results(train_data, predicted_vals, actual_vals, 'predictions.png')\n",
    "    prev_seq = train_x[-1]\n",
    "    predicted_vals = []\n",
    "    for i in range(20):\n",
    "        next_seq = predictor.test(sess, [prev_seq])\n",
    "        predicted_vals.append(next_seq[-1])\n",
    "        prev_seq = np.vstack((prev_seq[1:], next_seq[-1]))\n",
    "    plot_results(train_data, predicted_vals, actual_vals, 'hallucinations.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
