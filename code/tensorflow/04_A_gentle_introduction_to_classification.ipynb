{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using linear regression for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* classifier를 구현하기 위한 가장 간단한 방법 중 하나는 linear regression algorithm을 수정하는 것이다.\n",
    "* linear regression model은 f(x) = wx 같이 선형으로 보이는 함수들의 집합이며, 연속적인 실수를 입력으로 받아 연속적인 실수를 출력으로 생성한다.\n",
    "* 기억할 것은 classification은 연속이 아닌 이산 출력이란 점이다.\n",
    "* regression 모델이 두 가지 형태의 값을 출력할 경우, 어떠한 임계치를 주고 해당 임계치보다 높다면 1, 낮다면 0을 줄 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./fig/fig1.png\" />\n",
    "<img src=\"./fig/fig2.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터를 line으로 모델링했기 때문에 입력은 0~1 사이의 값을 출력으로 나타낼 수 있다.\n",
    "* 어떤 하나의 아이템이 하나의 카테고리에 속하는지 아니면 다른 카테고리에 속하는지를 결정해야 할 필요가 있으며, 대부분의 경우 0.5를 기준으로 판단한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x_label0 = np.random.normal(7,1,10)\n",
    "x_label1 = np.random.normal(2,1,10)\n",
    "#x_label0 = np.append(np.random.normal(7,1,9),20)\n",
    "xs = np.append(x_label0, x_label1)\n",
    "labels = [0.] * len(x_label0) + [1.] * len(x_label1)\n",
    "\n",
    "plt.scatter(xs, labels)\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "def model(X,w):\n",
    "    return tf.add(tf.mul(w[1], tf.pow(X,1)),\n",
    "                 tf.mul(w[0], tf.pow(X,0)))\n",
    "\n",
    "w = tf.Variable([0., 0.], name=\"parameters\")\n",
    "y_model = model(X, w)\n",
    "cost = tf.reduce_sum(tf.square(Y-y_model))\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(train_op, feed_dict={X: xs, Y: labels})\n",
    "    current_cost = sess.run(cost, feed_dict={X:xs, Y:labels})\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, current_cost)\n",
    "        \n",
    "w_val = sess.run(w)\n",
    "print('learning parameters', w_val)\n",
    "\n",
    "correct_prediction = tf.equal(Y, tf.to_float(tf.greater(y_model, 0.5)))\n",
    "\n",
    "test = tf.to_float(tf.greater(y_model, 0.5))\n",
    "\n",
    "print(sess.run(test, feed_dict={X:xs}))\n",
    "accuracy = tf.reduce_mean(tf.to_float(correct_prediction))\n",
    "\n",
    "print('accuracy', sess.run(accuracy, feed_dict={X:xs, Y: labels}))\n",
    "\n",
    "sess.close()\n",
    "\n",
    "all_xs = np.linspace(0,10, 100)\n",
    "plt.plot(all_xs, all_xs*w_val[1] + w_val[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using one-dimensional logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "x1 = np.random.normal(-4, 2, 1000)\n",
    "x2 = np.random.normal(4, 2, 1000)\n",
    "xs = np.append(x1, x2)\n",
    "ys = np.asarray([0.] * len(x1) + [1.] * len(x2))\n",
    "\n",
    "plt.scatter(xs,ys)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None,), name=\"x\")\n",
    "Y = tf.placeholder(tf.float32, shape=(None,), name=\"y\")\n",
    "w = tf.Variable([0., 0.], name=\"parameter\", trainable=True)\n",
    "y_model = tf.sigmoid(-(w[1] * X + w[0]))\n",
    "cost = tf.reduce_mean(-tf.log(y_model*Y + (1-y_model) * (1 - Y)))\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    prev_err = 0\n",
    "    for epoch in range(training_epochs):\n",
    "        err, _ = sess.run([cost, train_op], {X:xs, Y:ys})\n",
    "        print(epoch, err)\n",
    "        if abs(prev_err - err) < 0.0001:\n",
    "            break\n",
    "        prev_err = err\n",
    "    w_val = sess.run(w, {X:xs, Y: ys})\n",
    "    \n",
    "all_xs = np.linspace(-10, 10, 100)\n",
    "plt.plot(all_xs, sigmoid(-(all_xs * w_val[1] + w_val[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using two-dimensional logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "learning_rate = 0.1\n",
    "training_epochs = 2000\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "x1_label1 = np.random.normal(3, 1, 1000)\n",
    "x2_label1 = np.random.normal(2, 1, 1000)\n",
    "x1_label2 = np.random.normal(7, 1, 1000)\n",
    "x2_label2 = np.random.normal(6, 1, 1000)\n",
    "x1s = np.append(x1_label1, x1_label2)\n",
    "x2s = np.append(x2_label1, x2_label2)\n",
    "ys = np.asarray([0.] * len(x1_label1) + [1.] * len(x1_label2))\n",
    "\n",
    "X1 = tf.placeholder(tf.float32, shape=(None,), name=\"x1\")\n",
    "X2 = tf.placeholder(tf.float32, shape=(None,), name=\"x2\")\n",
    "Y = tf.placeholder(tf.float32, shape=(None,), name=\"y\")\n",
    "w = tf.Variable([0., 0., 0.], name=\"w\", trainable=True)\n",
    "\n",
    "y_model = tf.sigmoid(w[2] * X2 + w[1] * X1 + w[0])\n",
    "cost = tf.reduce_mean(-tf.log(y_model * Y + (1 - y_model) * (1-Y)))\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    prev_err = 0\n",
    "    for epoch in range(training_epochs):\n",
    "        err, _ = sess.run([cost, train_op], {X1: x1s, X2:x2s, Y:ys})\n",
    "        print(epoch, err)\n",
    "        if abs(prev_err - err) < 0.0001:\n",
    "            break\n",
    "        prev_err = err\n",
    "    w_val = sess.run(w, {X1: x1s, X2: x2s, Y: ys})\n",
    "    \n",
    "x1_boundary, x2_boundary = [], []\n",
    "for x1_test in np.linspace(0, 10, 100):\n",
    "    for x2_test in np.linspace(0, 10, 100):\n",
    "        z = sigmoid(x2_test*w_val[2] + x1_test*w_val[1] + w_val[0])\n",
    "        if abs(z - 0.5) < 0.01:\n",
    "            x1_boundary.append(x1_test)\n",
    "            x2_boundary.append(x2_test)\n",
    "            \n",
    "plt.scatter(x1_boundary, x2_boundary, c=\"b\", marker=\"o\", s=20)\n",
    "plt.scatter(x1_label1, x2_label1, c=\"r\", marker=\"x\", s=20)\n",
    "plt.scatter(x1_label2, x2_label2, c=\"g\", marker=\"1\", s=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualizing multiclass data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1_label0 = np.random.normal(1, 1, (100,1))\n",
    "x2_label0 = np.random.normal(1, 1, (100,1))\n",
    "x1_label1 = np.random.normal(5, 1, (100,1))\n",
    "x2_label1 = np.random.normal(4, 1, (100,1))\n",
    "x1_label2 = np.random.normal(8, 1, (100,1))\n",
    "x2_label2 = np.random.normal(0, 1, (100,1))\n",
    "\n",
    "plt.scatter(x1_label0, x2_label0, c='r', marker='o', s=60)\n",
    "plt.scatter(x1_label1, x2_label1, c='g', marker='x', s=60)\n",
    "plt.scatter(x1_label2, x2_label2, c='b', marker='_', s=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up training and test data for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs_label0 = np.hstack((x1_label0, x2_label0))\n",
    "xs_label1 = np.hstack((x1_label1, x2_label1))\n",
    "xs_label2 = np.hstack((x1_label2, x2_label2))\n",
    "xs = np.vstack((xs_label0, xs_label1, xs_label2))\n",
    "\n",
    "labels = np.matrix([[1., 0., 0.]] * len(x1_label0) + [[0., 1., 0.]] * len(x1_label1) + [[0., 0., 1.]] * len(x1_label2))\n",
    "\n",
    "arr = np.arange(xs.shape[0])\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "xs = xs[arr, :]\n",
    "\n",
    "labels = labels[arr, :]\n",
    "\n",
    "test_x1_label0 = np.random.normal(1, 1, (10,1))\n",
    "test_x2_label0 = np.random.normal(1, 1, (10,1))\n",
    "test_x1_label1 = np.random.normal(5, 1, (10,1))\n",
    "test_x2_label1 = np.random.normal(4, 1, (10,1))\n",
    "test_x1_label2 = np.random.normal(8, 1, (10,1))\n",
    "test_x2_label2 = np.random.normal(0, 1, (10,1))\n",
    "test_xs_label0 = np.hstack((test_x1_label0, test_x2_label0))\n",
    "test_xs_label1 = np.hstack((test_x1_label1, test_x2_label1))\n",
    "test_xs_label2 = np.hstack((test_x1_label2, test_x2_label2))\n",
    "\n",
    "test_xs = np.vstack((test_xs_label0, test_xs_label1, test_xs_label2))\n",
    "test_labels = np.matrix([[1., 0., 0.]] * 10 + [[0., 1., 0.]] * 10 + [[0., 0., 1.]] * 10)\n",
    "\n",
    "train_size, num_features = xs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using softmax regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "num_labels = 3\n",
    "batch_size = 100\n",
    "\n",
    "X = tf.placeholder(\"float\", shape=[None, num_features])\n",
    "Y = tf.placeholder(\"float\", shape=[None, num_labels])\n",
    "\n",
    "W = tf.Variable(tf.zeros([num_features, num_labels]))\n",
    "b = tf.Variable(tf.zeros([num_labels]))\n",
    "y_model = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = -tf.reduce_sum(Y * tf.log(y_model))\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for step in range(training_epochs * train_size // batch_size):\n",
    "        offset = (step * batch_size) % train_size\n",
    "        batch_xs = xs[offset:(offset+batch_size), :]\n",
    "        batch_labels = labels[offset:(offset+batch_size)]\n",
    "        err,_ = sess.run([cost, train_op], feed_dict={X: batch_xs, Y: batch_labels})\n",
    "        print (step,err)\n",
    "        W_val = sess.run(W)\n",
    "   #     print ('w', W_val)\n",
    "        b_val = sess.run(b)\n",
    "   #     print ('b', b_val)\n",
    "   #     print \"accuracy\", accuracy.eval(feed_dict={X: test_xs, Y: test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "10 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
