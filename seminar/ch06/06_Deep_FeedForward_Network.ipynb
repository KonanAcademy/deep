{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 Deep Feedfowrd Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 딥러닝 세미나 : 이론 [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* 6.1 Example: Learning XOR\n",
    "* 6.2 Gradient-Based Learning\n",
    "    - 6.2.1 Cost Functions\n",
    "        - 6.2.1.1 Learning Conditional Distributions with Maximum Likelihood\n",
    "        - 6.2.1.2 Learning Conditional Statistics \n",
    "    - 6.2.2 Output Units\n",
    "        - 6.2.2.1 Linear Units for Gaussian Output Distributions\n",
    "        - 6.2.2.2 Sigmoid Units for Bernoulli Output Distributions\n",
    "        - 6.2.2.3 Softmax Units for Multinoulli Output Distributions\n",
    "        - 6.2.2.4 Other Output Types\n",
    "* 6.3 Hidden Units\n",
    "    - 6.3.1 Rectiﬁed Linear Units and Their Generalizations\n",
    "    - 6.3.2 Logistic Sigmoid and Hyperbolic Tangent\n",
    "    - 6.3.3 Other Hidden Units\n",
    "* 6.4 Architecture Design\n",
    "    - 6.4.1 Universal Approximation Properties and Depth\n",
    "    - 6.4.2 Other Architectural Considerations\n",
    "* 6.5 Back-Propagation and Other Diﬀerentiation Algorithms\n",
    "    - 6.5.1 Computational Graphs\n",
    "    - 6.5.2 Chain Rule of Calculus\n",
    "    - 6.5.3 Recursively Applying the Chain Rule to Obtain Backprop\n",
    "    - 6.5.4 Back-Propagation Computation in Fully-Connected MLP\n",
    "    - 6.5.5 Symbol-to-Symbol Derivatives\n",
    "    - 6.5.6 General Back-Propagation\n",
    "    - 6.5.7 Example: Back-Propagation for MLP Training\n",
    "    - 6.5.8 Complications\n",
    "    - 6.5.9 Diﬀerentiation outside the Deep Learning Community\n",
    "    - 6.5.10 Higher-Order Derivatives\n",
    "* 6.6 Historical Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [2] L1 : From Machine Learning to Deep Learning (Udacity) -  https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63\n",
    "* [3] L1 : Deep Neural Networks (Udacity) https://drive.google.com/file/d/0B3vuuoFuJsKWdFFkMS10N1BpLTg/view\n",
    "* [4] CS231n: Convolutional Neural Networks for Visual Recognition : Image classification and the data-driven approach & k-nearest neighbor & Linear classification I - http://cs231n.stanford.edu/slides/winter1516_lecture2.pdf\n",
    "* [5] CS231n: Convolutional Neural Networks for Visual Recognition : Linear classification II & Higher-level representations, image features & Optimization, stochastic gradient descent - http://cs231n.stanford.edu/slides/winter1516_lecture3.pdf\n",
    "* [6] CS231n: Convolutional Neural Networks for Visual Recognition : Backpropagation & Introduction to neural networks - http://cs231n.stanford.edu/slides/winter1516_lecture4.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models are called feedforward because information ﬂows through thefunction being evaluated from x, through the intermediate computations used to deﬁne f, and ﬁnally to the output y. \n",
    "* There are no feedback connections in whichoutputs of the model are feedback into itself. \n",
    "* When feedforward neural networksare extended to include feedback connections, they are called recurrent neuralnetworks, presented in Chapter 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedforward neural networks are called networks because they are typically represented by composing together many diﬀerent functions.\n",
    "* The model is associatedwith a directed acyclic graph describing how the functions are composed together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, \n",
    "* we might have three functions $f^{(1)}$, $f^{(2)}$, and $f^{(3)}$ connected in a chain, to form f(x) = $f^{(3)}(f^{(2)}(f^{(1)}(x)))$.\n",
    "* $f^{(1)}$ is called the ﬁrst layer of the network, $f^{(2)}$ is called the second layer, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall length of the chain gives the depth of the model. \n",
    "* It is from this terminology that the name “deep learning” arises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ﬁnal layer of a feedforward network is called the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During neural network training, we drive f(x) to match $f^∗(x)$. \n",
    "* The training data provides us with noisy, approximate examples of $f^∗(x)$ evaluated at diﬀerent training points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each examplexis accompanied by a label $y ≈ f^∗(x)$.\n",
    "* The training examples specify directly what the output layer must do at each point x; \n",
    "* it must produce a value that is close to y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning algorithm must decidehow to use those layers to produce the desired output, but the training data does not say what each individual layer should do. * Instead, the learning algorithm mustdecide how to use these layers to best implement an approximation of $f^∗$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because the training data does not show the desired output for each of these layers, these layers are called hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, these networks are called neural because they are loosely inspired by neuroscience. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The goal of modern neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, modern neural network research is guided by many mathematical and engineering disciplines, and the goal of neural networks is not to perfectly model the brain. \n",
    "* It is best to think of feedforward networks as function approximation machines that are designed to achieve statistical generalization, occasionally drawing some insights from what we know about the brain, rather than as models of brain function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to understand feedforward networks is to begin with linear models and consider how to overcome their limitations. \n",
    "* Linear models, such as logistic regression and linear regression, are appealing because they may be ﬁt eﬃciently and reliably, either in closed form or with convex optimization. \n",
    "* Linear models also have the obvious defect that the model capacity is limited to linear functions, so the model cannot understand the interaction between any two input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nonlinear transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extend linear models to represent nonlinear functions of x, we can apply the linear model not to x itself but to a transformed input φ(x), where φis a nonlinear transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The question is then how to choose the mapping φ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.One option is to use a very generic φ, such as the inﬁnite-dimensional φ that is implicitly used by kernel machines based on the RBF kernel. \n",
    "* If φ(x) is of high enough dimension, we can always have enough capacity to ﬁt thetraining set, but generalization to the test set often remains poor. \n",
    "* Very generic feature mappings are usually based only on the principle of local smoothness and do not encode enough prior information to solve advanced problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Another option is to manually engineer φ.\n",
    "* Until the advent of deep learning, this was the dominant approach. \n",
    "* This approach requires decades of human eﬀort for each separate task, with practitioners specializing in diﬀerent domains such as speech recognition or computer vision, and with little transfer between domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.The strategy of deep learning is to learn φ. \n",
    "* In this approach, we have a model y = f(x;θ,w) = $φ(x;θ)^{\\top}w$. \n",
    "* We now have parameters θ that we use to learn φ from a broad class of functions, and parameters w that map from φ(x) to the desired output. \n",
    "* This is an example of a deep feedforward network, with φ deﬁning a hidden layer. \n",
    "* This approach is the only one of the three that gives up on the convexity of the training problem, but the beneﬁts outweigh the harms. \n",
    "* In this approach, we parametrize the representation as φ(x;θ) and use the optimization algorithm to ﬁnd the θ that corresponds to a good representation. \n",
    "* If we wish, this approach can capture the beneﬁt of the ﬁrst approach by being highly generic—we do so by using a very broad family φ(x;θ). \n",
    "* This approach can also capture the beneﬁt of the second approach.\n",
    "* Human practitioners can encode their knowledge to help generalization by designing families φ(x;θ) that they expect will perform well. \n",
    "* The advantage is that the human designer only needs to ﬁnd the right general function family rather than ﬁnding precisely the right function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Example: Learning XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XOR function (“exclusive or”) is an operation on two binary values,x1 and x2. When exactly one of these binary values is equal to 1, the XOR function returns 1. Otherwise, it returns 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can treat this problem as a regression problem and use a mean squared error loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Linear_least_squares_example2.svg/500px-Linear_least_squares_example2.svg.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example, we will not be concerned with statistical generalization.We want our network to perform correctly on the four points X={ $[0,0]^{\\top}$,  $[0,1]^{\\top}$, $[1,0]^{\\top}$, and $[1,1]^{\\top}$}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After solving the normal equations, we obtain w=0 and b=1/2. The linear model simply outputs 0.5 everywhere. Why does this happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speciﬁcally, we will introduce a very simple feedforward network with onehidden layer containing two hidden units. See Fig. 6.2 for an illustration of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f^{(1)}(x;W,c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h=^{f(1)}(x;W,c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y=f^{(2)}(h;w,b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(x;W,c,w,b) = $f^{(2)}(f^{(1)}(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f^{(1)}(x)=W^{\\top}x$ and $f^{(2)}(h)=h^{\\top}w$. Then $f(x)=w^{\\top}W^{\\top}x$. We could represent this function as f(x) = $x^{\\top}w^{\\prime}$ where $w^{\\prime}= Ww$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h=g(W^{\\top}x+c)$,where W provides the weights of a linear transformation and c the biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation functiong is typically chosen to be a function that is applied element-wise, with $h_{i}=g(x^{\\top}W:,_{i}+c_{i})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rectiﬁed linear unit or ReLU\n",
    "g(z) = max{0, z}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this example, we simply speciﬁed the solution, then showed that it obtained zero error. \n",
    "* In a real situation, there might be billions of model parameters and billions of training examples, so one cannot simply guess the solution as we did here. \n",
    "* <font color=\"red\">Instead, a gradient-based optimization algorithm can ﬁnd parameters thatproduce very little error.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Gradient-Based Learning\n",
    "* 6.2.1 Cost Functions\n",
    "* 6.2.2 Output Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Designing and training a neural network is not much diﬀerent from training any other machine learning model with gradient descent.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://qph.is.quoracdn.net/main-qimg-46a77c77c721ba34283308232a1788c8?convert_to_webp=true\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">The largest diﬀerence between the linear models we have seen so far and neural networks is that the nonlinearity of a neural network causes most interesting loss functions to become non-convex.  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [7] Convex analysis - https://msampler.wordpress.com/2009/07/08/convex-analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://msampler.files.wordpress.com/2009/07/cvx-fun.gif\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stocastic gradient decent VS others(linear equation solver, convex optimization) \n",
    "* This means that neural networks are usually trained by using iterative, gradient-based optimizers that merely <font color=\"red\">drive the cost function to a very low value</font>, rather than the linear equation solvers used to train linear regression models or the convex optimization algorithms with global convergence guarantees used to train logistic regression or SVMs.\n",
    "* Convex optimization converges starting from any initial parameters (in theory—in practice it is very robust but can encounter numerical problems). \n",
    "* Stochastic gradient descent appliedto non-convex loss functions has <font color=\"red\">no such convergence guarantee</font>, and is <font color=\"red\">sensitive to the values of the initial parameters</font>.\n",
    "* <font color=\"blue\">For feedforward neural networks, it is important to initialize all weights to small random values. The biases may be initialized to zero or to small positive values.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://camo.githubusercontent.com/30bf2d42d3a9b0e07dbc03a014f4e36dbc06904f/68747470733a2f2f7261772e6769746875622e636f6d2f7175696e6e6c69752f4d616368696e654c6561726e696e672f6d61737465722f696d61676573466f724578706c616e6174696f6e2f4772616469656e7444657363656e74576974684d75746c69706c654c6f63616c4d696e696d756d2e6a7067\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.holehouse.org/mlclass/17_Large_Scale_Machine_Learning_files/Image%20[16].png\"   />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://43284bdcf41602d9ee3b7f9155623bc4db1a5d55.googledrive.com/host/0B56ak7W-HmqASVBYZTJ1WXVoQUU/img/stochastic.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.slidesharecdn.com/nn-150216124050-conversion-gate01/95/neural-networks-overview-11-638.jpg?cb=1424102465\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can of course, train models such as linear regression and support vector machines with gradient descent too, and in fact this is <font color=\"red\">common when the trainingset is extremely large.</font>\n",
    "* From this point of view, training a neural network is notmuch diﬀerent from training any other model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with other machine learning models, <font color=\"red\">to apply gradient-based learning</font> we must choose a <font color=\"blue\">cost function</font>, and we must choose how to <font color=\"blue\">represent the output of the model</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total cost function used to train a neural network will often combine one of the primary cost functions described here with a <font color=\"red\">regularization term</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.1 Cost Functions\n",
    "* 6.2.1.1 Learning Conditional Distributions with Maximum Likelihood\n",
    "* 6.2.1.2 Learning Conditional Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important aspect of the design of a deep neural network is the <font color=\"red\">choice of the cost function</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### priciple of of maximum likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(y | x;θ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In most cases, our <font color=\"red\">parametric model</font> deﬁnes a distributionp(y|x;θ) and we simply use the <font color=\"blue\">principle of maximum likelihood</font>. \n",
    "* This means we use the <font color=\"red\">cross-entropy</font> <font color=\"blue\">between the training data and the model’s predictions</font> as the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://statgen.iop.kcl.ac.uk/media/ml1.gif\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Mplwp_shannon_entropy.svg/2000px-Mplwp_shannon_entropy.svg.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://colah.github.io/posts/2015-09-Visual-Information/img/CrossEntropyDef.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/math/5/7/9/57915b0c4d0e62a602db5e757742b1d3.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cfile4.uf.tistory.com/image/2645033951991C20193341\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63/res/1ff6f90c-d594-468b-86a2-d70289958ce8.png?resizeSmall&width=832\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.slidesharecdn.com/215implementingdeeplearningusingcudnn-150915052020-lva1-app6892/95/251-implementing-deep-learning-using-cu-dnn-17-638.jpg?cb=1442295596\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/svmvssoftmax.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://images.slideplayer.com/11/3277991/slides/slide_57.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://qph.is.quoracdn.net/main-qimg-9e2d012ef7cb8b29d2bed14d2975c986?convert_to_webp=true\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://qiita-image-store.s3.amazonaws.com/0/100523/195fb6d9-adf6-9166-5c81-08665777032d.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://2.bp.blogspot.com/-EVROdmAZ0No/VoTHrtrREZI/AAAAAAAAAn0/gyKG0BUjst8/s1600/softmax-regression-scalargraph.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63/res/d6f7961c-b05d-495d-af14-4d6a21feecdf.png?resizeSmall&width=832\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1.1 Learning Conditional Distributions with Maximum Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://statgen.iop.kcl.ac.uk/media/ml2.gif\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63/res/d6f7961c-b05d-495d-af14-4d6a21feecdf.png?resizeSmall&width=832\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most modern neural networks are trained using maximum likelihood. This means that the cost function is simply the <font color=\"red\">negative log-likelihood</font>, <font color=\"blue\">equivalently described as the cross-entropy between the training data and the model distribution</font>. This cost function is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speciﬁc form of the cost function changes from model to model, dependingon the speciﬁc form of $log p_{model}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if $p_{model}(y|x) = N(y;f(x;θ),I)$,then we recover the mean squared error cost,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "up to a scaling factor of $\\frac{1}{2}$ and a term that does not depend on θ. The discarded constant is based on the variance of the Gaussian distribution, which in this casewe chose not to parametrize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we saw that the equivalence between maximum likelihood estimation with an output distribution and minimization of mean squared error holds for a linear model, but in fact, the equivalence holds regardless of the f(x; θ) used to predict the mean of the Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">An advantage of this approach of deriving the cost function from maximum likelihood is that it removes the burden of designing cost functions for each model</font>.  Specifying a model $p(y|x)$ automatically determines a cost function $logp(y|x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">One recurring theme throughout neural network design is that the gradient ofthe cost function must be large and predictable enough to serve as a good guidefor the learning algorithm.</font>\n",
    "* Functions that saturate (become very ﬂat) undermine this objective because they make the gradient become very small. \n",
    "* In many cases this happens because the activation functions used to produce the output of thehidden units or the output units saturate.\n",
    "* <font color=\"red\">The negative log-likelihood helps to avoid this problem for many models</font>. \n",
    "    - Many output units involve an exp function that can saturate when its argument is very negative.\n",
    "    - The log function in the negative log-likelihood cost function undoes the exp of some output units. \n",
    "    - We will discuss the interaction between the cost function and the choice of output unit inSec. 6.2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">One unusual property of the cross-entropy cost used to perform maximum likelihood estimation</font> is that it usually does not have a minimum value when applied to the models commonly used in practice.\n",
    "* <font color=\"blue\">For discrete output variables</font>, most models are parametrized in such a way that they <font color=\"blue\">cannot represent a probability of zero or one, but can come arbitrarily close to doing so</font>. Logistic regressionis an example of such a model.\n",
    "* <font color=\"red\">For real-valued output variables</font>, if the model can control the <font color=\"red\">density of the output distribution</font> (for example, by learning the variance parameter of a Gaussian output distribution) then it <font color=\"red\">becomes possible to assign extremely high density</font> to the correct training set outputs, resulting <font color=\"red\">in cross-entropy approaching negative inﬁnity</font>.\n",
    "* <font color=\"blue\">Regularization techniques</font> described in Chapter 7 provide several diﬀerent ways of modifying the learning problem sothat the model cannot reap unlimited reward in this way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1.2 Learning Conditional Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.mwclearning.com/wp-content/uploads/2011/04/conditionalProb.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.cvlibs.net/projects/gausspro/gausspro02.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of learning a full probability distribution p(y|x;θ) we often want to learn just one conditional statistic of y given x.\n",
    "* For example, we may have a predictor f(x;θ) that we wish to predict the mean of y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">If we use a suﬃciently powerful neural network</font>, <font color=\"blue\">we can think of the neural network as being able to represent any function $f$ from a wide class of functions</font>, with this class being limited only by features such as continuity and boundedness rather than by having a speciﬁc parametric form.\n",
    "* From this point of view, <font color=\"blue\">we can view the cost function as being a functional</font> rather than just a function. \n",
    "    - A functional is a mapping from functions to real numbers.\n",
    "* <font color=\"red\">We can thus think of learning as choosing a function rather than merely choosing a set of parameters</font>.\n",
    "* <font color=\"blue\">We can design our cost functional to have its minimum occur at some speciﬁcfunction we desire.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculus of variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving an <font color=\"red\">optimization problem with respect to a function</font> requires a mathematical tool called calculus of variations, described in Sec. 19.4.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculus of variations may be used to derive the following two results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* so long as this function lies within the class we optimize over. \n",
    "* In other words, if we could train on inﬁnitely many samples from the true data-generating distribution, minimizing the mean squared error cost function gives a function that predicts the mean of y for each value of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, <font color=\"red\">mean squared error and mean absolute error often lead to poor results when used with gradient-based optimization</font>. \n",
    "* Some output units that saturate produce very small \n",
    "* <font color=\"blue\">This is one reason that the cross-entropy cost function is more popular</font> than mean squared error or mean absolute error, even when it is not necessary to estimate an entire distribution p(y|x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.2 Output Units\n",
    "* 6.2.2.1 Linear Units for Gaussian Output Distributions\n",
    "* 6.2.2.2 Sigmoid Units for Bernoulli Output Distributions\n",
    "* 6.2.2.3 Softmax Units for Multinoulli Output Distributions\n",
    "* 6.2.2.4 Other Output Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/nn1/neuron_model.jpeg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">The choice of cost function is tightly coupled with the choice of output unit</font>\n",
    "* Most of the time, we simply use the cross-entropy between the data distribution and the model distribution. \n",
    "* <font color=\"blue\">The choice of how to represent the output then determines the form of the cross-entropy function</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this section, we suppose that the feedforward network provides a set of hidden features deﬁned by h=f(x;θ). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The role of the output layer is then to provide some additional transformation from the features to complete the task that the network must perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2.1 Linear Units for Gaussian Output Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [8] Affie Transformation - https://en.wikipedia.org/wiki/Affine_transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.publiclab.org/system/images/photos/000/004/507/original/geometric-transformations.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/350px-Normal_Distribution_PDF.svg.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple kind of output unit is an output unit based on an <font color=\"red\">aﬃne transformation with no nonlinearity</font>. These are often just called linear units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.13.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximizing the log-likelihood is then equivalent to minimizing the mean squared error\n",
    "* The maximum likelihood framework \n",
    "    - makes it straight forward to learn the covariance of the Gaussian too, or \n",
    "    - to make the covariance of the Gaussian be a function of the input. \n",
    "    - However, the covariance must be constrained to be a positive deﬁnite matrix for all inputs. \n",
    "    - It is diﬃcult to satisfy such constraints with a linear output layer, so typically other output units are used to parametrize the covariance.\n",
    "    - Approaches to modeling the covariance are described shortly, in Sec. 6.2.2.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2.2 Sigmoid Units for Bernoulli Output Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://artint.info/figures/ch07/sigmoidc.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://chi.se.wtb.tue.nl/_images/binomial.svg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many tasks require <font color=\"red\">predicting the value of a binary variable y</font>. Classiﬁcation problems with <font color=\"blue\">two classes</font> can be cast in this form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A Bernoulli distribution is deﬁned by just a single number. \n",
    "* The neural net needs to predict only $P(y=1|x)$.\n",
    "* For this number to be a valid probability, itmust lie in the interval [0, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear unit case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wereto use a linear unit, and threshold its value to obtain a valid probability:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.14.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This would indeed deﬁne a valid conditional distribution, but we would <font color=\"red\">not be able to train it very eﬀectively with gradient descent</font>. \n",
    "* Any time that $w^{\\top}h+b$ strayed outside the unit interval, <font color=\"blue\">the gradient of the output of the model with respect to its parameters would be 0</font>. \n",
    "* <font color=\"red\">A gradient of 0 is typically problematic</font> because the learning algorithm <font color=\"red\">no longer has a guide for how to improve the corresponding parameters</font>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://nbviewer.jupyter.org/github/psygrammer/qgm/blob/master/part3/connectionist/ch01/figures/cap1.11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid output unit case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sigmoid output unit is deﬁned by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.15.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where σ is the logistic sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of the sigmoid output unit as having two components. \n",
    "* First, ituses a linear layer to compute $z=w^{\\top}h+b$.\n",
    "* Next, it <font color=\"red\">uses the sigmoid activation function to convert z into a probability</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid can be motivated by constructing an unnormalized probability distribution $P^\\sim(y)$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/svmvssoftmax.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://oakmachine.com/img/multinomial-logistic-classification-diagram.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nomarlizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then divide by an appropriate constant to obtain a valid probability distribution. If we begin with the assumption that the unnormalized log probabilities are linear inyandz, we can exponentiate to obtain the unnormalized probabilities. We then normalize to see that this <font color=\"red\">yields a Bernoulli distribution controlled by a sigmoidal transformation of z</font>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.16.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Probability distributions based on exponentiation and normalization are commonthroughout the statistical modeling literature. \n",
    "* The z variable deﬁning such a distribution over binary variables is called a <font color=\"red\">logit</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach to predicting the probabilities in log-space is natural to use with maximum likelihood learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the cost function used with maximum likelihood is −log P(y | x), the login the cost function undoes the exp of the sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color=\"red\">The loss function</font> for maximum likelihood learning of a <font color=\"red\">Bernoulli parametrized by a sigmoid</font> is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.17.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* y rewriting the loss in terms of the softplus function, we can see that it <font color=\"red\">saturates only when (1−2y)z is very negative</font>.\n",
    "* Saturation thus occurs only \n",
    "    - when the model already has the right answer — when \n",
    "        - y = 1 and z is very positive, or\n",
    "        - y = 0 and z is very negative. \n",
    "* When z has the wrong sign, the argument to the softplus function, (1−2y)z, may be simpliﬁed to|z|. \n",
    "    - As |z| becomes large while z has the wrong sign, \n",
    "        - the softplus function asymptotes toward simply returning its argument |z|. \n",
    "     - The derivative with respect to z asymptotes to sign(z), so, in the limit of extremely incorrect z, \n",
    "         - the softplus function does not shrink the gradient at all. \n",
    "             - <font color=\"red\">This property is very useful because it means that gradient-based learning can act to quickly correct a mistaken z</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고 : Softpuls function\n",
    "ReLU can be approximated by a so called softplus function (for which the derivative is the logistic functions):\n",
    "\n",
    "g(x) = log(1+exp(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://imiloainf.files.wordpress.com/2013/11/activation_funcs1.png\" with=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other loss functions\n",
    "* When we use other loss functions such as \n",
    "    - mean squared error, \n",
    "        - the loss can saturate anytime σ(z) saturates. \n",
    "* The sigmoid activation function saturates to 0 \n",
    "    - when z becomes very negative and saturates to 1\n",
    "    - when z becomes very positive.\n",
    "    - The gradient can shrink too small to be useful for learning \n",
    "        - whenever this happens, \n",
    "        - whether the model has the correct answer or the incorrect answer. \n",
    "* <font color=\"red\">For this reason, maximum likelihood is almost always the preferred approach to training sigmoid output units</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### negative log-likelihood\n",
    "* Analytically, the logarithm of the sigmoid is always deﬁned and ﬁnite, \n",
    "    - because the sigmoid returns values restricted to the open interval (0,1), \n",
    "        - rather than using the entire closed interval of valid probabilities [0,1]. \n",
    "* In software implementations,to avoid numerical problems,\n",
    "    - it is <font color=\"red\">best to write the negative log-likelihood as a function of z</font>, \n",
    "        - rather than as a function of $\\hat{y}=σ(z)$. \n",
    "             - If the sigmoid function underﬂows to zero, then taking the logarithm of $\\hat{y}$ yields negative inﬁnity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2.3 Softmax Units for Multinoulli Output Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/math/0/9/9/0991837b7d5a522ebc156f51dadbed0e.png\" />\n",
    "<img src=\"https://qph.cr.quoracdn.net/main-qimg-9e2d012ef7cb8b29d2bed14d2975c986\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/math/4/7/f/47f3344c0d641fa910088ca66cd1ecf8.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.slidesharecdn.com/machinelearningmeetup-12-18-2013-140115184408-phpapp01/95/digging-into-the-dirichlet-distribution-by-max-sklar-11-638.jpg?cb=1389811694\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.mathworks.com/help/stats/multinomial_plot2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any time we wish to represent a probability distribution over a <font color=\"red\">discrete variable with n possible values</font>, we may <font color=\"blue\">use the softmax function</font>. \n",
    "* This can be seen as a <font color=\"red\">generalization of the sigmoid function</font> which was used to represent a probability distribution over a binary variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/svmvssoftmax.png\" width=600 />\n",
    "<img src=\"http://oakmachine.com/img/multinomial-logistic-classification-diagram.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### binary case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of binary variables, we wished to produce a single number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.18.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this number needed to lie between 0 and 1, and because we wanted thelogarithm of the number to be well-behaved for gradient-based optimization ofthe log-likelihood, we chose to instead predict a number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.19.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exponentiating and normalizing gave us a Bernoulli distribution controlled by the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">To generalize to the case of a discrete variable with n values</font>, we now need to produce a vector $\\hat{y}$, with $\\hat{y}_{i}=P(y=i|x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same approach that worked for the Bernoulli distribution generalizes to the multinoulli distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a linear layer predicts unnormalized log probabilities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.20.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.21.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The <font color=\"red\">ﬁrst term</font> of Eq. 6.30 shows that the input $z_{i}$ always has a <font color=\"red\">direct contribution to the cost function</font>.\n",
    "    - Because this term cannot saturate, we know that learning can proceed, even if the contribution of $z_{i}$ to the second term of Eq. 6.30 becomes very small.\n",
    "    - When maximizing the log-likelihood, the ﬁrst term encourages $z_{i}$ to be pushed up, while the second term encourages all of z to be pushed down.\n",
    "* The intuition, for <font color=\"blue\">the second term</font>, we can gain from this approximation is that the negative log-likelihood cost function always <font color=\"blue\">strongly penalizes the most active incorrect prediction</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unregularized maximum likelihood case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, unregularized maximum likelihood will drive the model to learn parameters that drive the softmax to predict the fraction of counts of each outcome observed in the training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.22.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because maximum likelihood is a consistent estimator, this is <font color=\"blue\">guaranteed to happen so long as the model family is capable of representing the training distribution</font>. \n",
    "* In practice, <font color=\"red\">limited model capacity and imperfect optimization</font> will mean that <font color=\"red\">the model is only able to approximate these fractions</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other objective functions \n",
    "<font color=\"red\">Many objective functions other than the log-likelihood do not work as well with the softmax function</font>. \n",
    "* Speciﬁcally, <font color=\"blue\">objective functions that do not use a log to undo the exp of the softmax fail to learn</font> when the argument to the exp becomes very negative, <font color=\"blue\">causing the gradient to vanish</font>. \n",
    "* In particular, <font color=\"red\">squared error is a poor loss function for softmax units, and can fail to train</font> the model to change its output, even when the model makes highly conﬁdent incorrect predictions (Bridle,1990). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">To understand why these other loss functions can fail, we need to examine the softmax function itself</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### examine the softmax function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/math/0/9/9/0991837b7d5a522ebc156f51dadbed0e.png\" />\n",
    "<img src=\"https://qph.cr.quoracdn.net/main-qimg-9e2d012ef7cb8b29d2bed14d2975c986\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Like the sigmoid, the softmax activation can saturate</font>\n",
    "* In the case of the softmax, there are multiple output values. These output values can saturate <font color=\"red\">when the diﬀerences between input values become extreme</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see that the softmax function responds to the diﬀerence between its inputs,observe that the <font color=\"blue\">softmax output is invariant to adding the same scalar to all of its inputs</font>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.23.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this property, we can derive a numerically stable variant of the softmax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.24.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The reformulated version allows us to evaluate <font color=\"red\">softmax with only small numerical errors</font> even <font color=\"blue\">when z contains extremely large or extremely negative numbers</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2.4 Other Output Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"blue\">The linear, sigmoid, and softmax output units</font> described above are the <font color=\"blue\">most common</font>. \n",
    "* Neural networks can generalize to almost <font color=\"red\">any kind of output layer that we wish</font>.\n",
    "* <font color=\"red\">The principle of maximum likelihood provides a guide for how to design</font> a good cost function for nearly any kind of output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we define a conditional distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.25.png\" width=100/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the principle of maximum likelihood suggests we use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.26.png\" width=200 /> as our cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### neural network as representing a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we can think of the neural network as representing a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.27.png\" width=100 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of this function are not direct predictions of the value y. Instead, $f(x;θ)=ω$ provides the parameters for a distribution over y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our loss functioncan then be interpreted as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.29.png\" width=200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example : we may wish to learn the variance of a conditional Gaussian for y, given x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.cvlibs.net/projects/gausspro/gausspro02.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the simple case,\n",
    "    <img src=\"http://hyperphysics.phy-astr.gsu.edu/hbase/math/immath/gauds.gif\" width=300 />\n",
    "    - where the variance $σ^{2}$ is a constant, \n",
    "    - there is a closed form expression \n",
    "        - because the maximum likelihood estimator of variance is simply the empirical mean of the squared diﬀerence \n",
    "            - between observations y and their expected value. \n",
    "    - A computationally more expensive approach that \n",
    "        - does not require writing special-case code \n",
    "        - is to simply include the variance \n",
    "            - as one of the properties of the distribution \n",
    "                - $p(y | x)$ that is controlled by \n",
    "                    - $ω=f(x;θ)$. \n",
    "    - The negative log-likelihood \n",
    "        - $−log p(y;ω(x))$ \n",
    "        - will then provide a cost function \n",
    "            - with the appropriate terms necessary \n",
    "                - to make our optimization procedure incrementally learn the variance. \n",
    "* In the simple case \n",
    "    - where the standard deviation does not depend on the input, \n",
    "    - we can make a new parameter in the network that \n",
    "        - is copied directly into ω. \n",
    "    - This new parameter \n",
    "        - might be $σ$ itself or \n",
    "        - could be a parameter $v$ representing $σ^{2}$ or \n",
    "        - it could be a parameter β representing $1/σ^{2}$, \n",
    "        - depending on how we choose to parametrize the distribution. \n",
    "* We may wish our model to predict \n",
    "    - a diﬀerent amount of variance in y \n",
    "        - for diﬀerent values of x. \n",
    "    - This is called a heteroscedastic model. \n",
    "        <img src=\"http://gerardnico.com/wiki/_media/statistics/heteroscedasticity.jpg\" width=400 />\n",
    "    - In the heteroscedastic case, \n",
    "        - we simply make \n",
    "            - the speciﬁcation of the variance \n",
    "                - be one of the values output by $f(x;θ)$. \n",
    "            - A typical way to do this is to formulate \n",
    "                - the Gaussian distribution \n",
    "                    - using precision, \n",
    "                        - rather than variance, as described in Eq.3.22.\n",
    "                        <img src=\"figures/eq3.22.png\" width=400 />\n",
    "                        <img src=\"http://www.paulbays.com/code/JV10/fig2.gif\" width=300 />\n",
    "* In the multivariate case\n",
    "    <img src=\"http://i.stack.imgur.com/qqG5Y.png\" width=300 />\n",
    "    - it is most common to use a diagonal precision matrix\n",
    "        <img src=\"figures/cap6.37.png\" width=400 />\n",
    "    - This formulation works well with gradient descent \n",
    "        - because the formula for the log-likelihood of the Gaussian distribution \n",
    "            - parametrized by $β$ involves only \n",
    "                - multiplication by $β_{i}$ and \n",
    "                - addition of log $β_{i}$. \n",
    "            - The gradient of \n",
    "                - multiplication, \n",
    "                - addition, and \n",
    "                - logarithm operations \n",
    "            - is well-behaved. \n",
    "    - By comparison, \n",
    "        - if we parametrized theoutput in terms of variance,\n",
    "            - we would need to use division. \n",
    "                - The division function becomes arbitrarily steep near zero.\n",
    "            - While large gradients can help learning,\n",
    "                - arbitrarily large gradients usually result in instability. \n",
    "        - If we parametrized theoutput in terms of standard deviation,\n",
    "            - the log-likelihood would still involve division, and would also involve squaring. \n",
    "            - The gradient through the squaring operation can vanish near zero, making it diﬃcult to learn parameters that are squared.\n",
    "    - Regardless of whether we use standard deviation, variance, or precision, we must ensure that \n",
    "        - the covariance matrix of the Gaussian is positive deﬁnite.\n",
    "            - Becausethe eigenvalues of the precision matrix are the reciprocals of the eigenvalues of the covariance matrix, \n",
    "            - this is equivalent to ensuring that the precision matrix is positive deﬁnite. \n",
    "        - If we use \n",
    "            - a diagonal matrix, or \n",
    "            - a scalar times the diagonal matrix,\n",
    "        - then the only condition we need to enforce on the output of the model is positivity.\n",
    "* If we suppose that \n",
    "    - $a$ is the raw activation of the model\n",
    "        - used to determine the diagonal precision, \n",
    "    - we can use \n",
    "        - the softplus function \n",
    "            - to obtain a positive precision vector :\n",
    "            <img src=\"figures/cap6.42.png\" width=100 />\n",
    "* This same strategy applies equally if using variance or standard deviation rather than precision or if using a scalar times identity rather than diagonal matrix.\n",
    "    - softpuls : g(x) = log(1+exp(x))\n",
    "    <img src=\"https://imiloainf.files.wordpress.com/2013/11/activation_funcs1.png\" with=300 />\n",
    "* It is rare to learn a covariance or precision matrix with richer structure than diagonal.\n",
    "    - If the covariance is full and conditional, \n",
    "        - then a parametrization must be chosen \n",
    "            - that guarantees positive-deﬁniteness of \n",
    "                - the predicted covariance matrix.\n",
    "        - This can be achieved by writing\n",
    "            <img src=\"figures/cap6.43.png\" width=300 />\n",
    "            where $B$ is an unconstrained square matrix.\n",
    "        - One practical issue if the matrix is full rank is that computing the likelihood is expensive, with\n",
    "            <img src=\"figures/cap6.45.png\" width=300 />\n",
    "        - computation for the determinant and \n",
    "            <img src=\"figures/cap6.46.png\" width=200 />\n",
    "        - (or equivalently, and more commonly done, its eigendecomposition or that of $B(x)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example : multimodal regression = Neural networks with Gaussian mixtures = mixture density networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We often want to perform multimodal regression, that is, \n",
    "    - to predict real values that \n",
    "        - come from  a conditional distributionp $(y|x)$ that can have\n",
    "            - several diﬀerent peaks in $y$ space for \n",
    "                - the same value of $x$. \n",
    "* In this case, a Gaussian mixture is a natural representation for the output\n",
    "    <img src=\"http://courses.ee.sun.ac.za/Pattern_Recognition_813/lectures/lecture06/img2.png\" width=300 />\n",
    "* Neural networks with Gaussian mixtures as their output are often called mixture density networks.\n",
    "    ##### 참고\n",
    "    * [9] Mixture Density Networks with TensorFlow - http://blog.otoro.net/2015/11/24/mixture-density-networks-with-tensorflow/\n",
    "* A Gaussian mixture output with $n$ components is deﬁned by the conditional probability distribution\n",
    "    <img src=\"figures/cap6.48.png\" width=400 />\n",
    "<img src=\"figures/cap6.49.png\" width=600 />\n",
    "    - 1.Mixture components $p(c=i|x)$: \n",
    "        - these form a multinoulli distribution over the $n$ diﬀerent components associated with latent variable $c$, \n",
    "        - and can typically be obtained by a softmax over an n-dimensional vector, \n",
    "            - to guarantee that these outputs are positive and sum to 1\n",
    "    - 2.<img src=\"figures/cap6.51.png\" width=200 />\n",
    "        - these indicate the center or mean associated with the i-th Gaussian component, and are unconstrained (typically with no nonlinearity at all for these output units).\n",
    "    - 3.<img src=\"figures/cap6.52.png\" width=200 /> \n",
    "        -  these specify the covariance matrix for each component $i$. \n",
    "        - As when learning a single Gaussian component, we typically use a diagonal matrix to avoid needing to compute determinants.\n",
    "* It has been reported that gradient-based optimization of conditional Gaussian mixtures (on the output of neural networks) \n",
    "    - can be unreliable, \n",
    "    - in part because one gets divisions (by the variance) \n",
    "        - which can be numerically unstable \n",
    "            - (when some variance gets to be small for a particular example, yielding very large gradients).\n",
    "    - One solution is to \n",
    "        - clip gradients (see Sec. 10.11.1) \n",
    "            - while another is to scale the gradients heuristically\n",
    "* Gaussian mixture outputs are particularly eﬀective \n",
    "    - in generative models of speech (Schuster, 1999) or \n",
    "    - movements of physical objects (Graves, 2013). \n",
    "    - The mixture density strategy gives a way for the network \n",
    "        - to represent multiple output modes and \n",
    "        - to control the variance of its output, \n",
    "            - which is crucial for obtaining a high degree of quality in these real-valued domains. \n",
    "* An example of a mixture density network is shown in Fig.6.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.53.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we may wish to continue to model larger vectors $y$ containing more variables, and to impose <font color=\"red\">richer and richer structures on these output variables</font>.\n",
    "* For example, we may wish for our neural network to output a sequence of characters that forms a sentence.\n",
    "    - In these cases, we may continue \n",
    "        - to use the principle of maximum likelihood applied to our model $p(y;ω(x))$, \n",
    "        - but the model we use to describeybecomes complex enough to be beyond the scope of this chapter.\n",
    "* <font color=\"blue\">Chapter 10</font> describes how to use recurrent neural networks to deﬁne such <font color=\"blue\">models over sequences</font>, and \n",
    "* <font color=\"red\">Part III</font> describes advanced techniques for <font color=\"red\">modeling arbitrary probability distributions</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 Hidden Units\n",
    "* 6.3.1 Rectiﬁed Linear Units and Their Generalizations\n",
    "* 6.3.2 Logistic Sigmoid and Hyperbolic Tangent\n",
    "* 6.3.3 Other Hidden Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">how to choose the type of hidden unit to use in the hidden layers of the model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">The design of hidden units is an extremely active area of research and does not yet have many deﬁnitive guiding theoretical principles.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">Rectiﬁed linear units are an excellent default choice of hidden unit.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.54.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.55.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.1 Rectiﬁed Linear Units and Their Generalizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.56.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.57.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.58.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.2 Logistic Sigmoid and Hyperbolic Tangent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.59.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.60.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.61.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.62.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.3 Other Hidden Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.63.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.64.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.65.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.66.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.67.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.68.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4 Architecture Design\n",
    "* 6.4.1 Universal Approximation Properties and Depth\n",
    "* 6.4.2 Other Architectural Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.69.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.70.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.1 Universal Approximation Properties and Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.71.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.72.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.73.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.74.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.75.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.76.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.2 Other Architectural Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.77.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.78.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5 Back-Propagation and Other Diﬀerentiation Algorithms\n",
    "* 6.5.1 Computational Graphs\n",
    "* 6.5.2 Chain Rule of Calculus\n",
    "* 6.5.3 Recursively Applying the Chain Rule to Obtain Backprop\n",
    "* 6.5.4 Back-Propagation Computation in Fully-Connected MLP\n",
    "* 6.5.5 Symbol-to-Symbol Derivatives\n",
    "* 6.5.6 General Back-Propagation\n",
    "* 6.5.7 Example: Back-Propagation for MLP Training\n",
    "* 6.5.8 Complications\n",
    "* 6.5.9 Diﬀerentiation outside the Deep Learning Community\n",
    "* 6.5.10 Higher-Order Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.79.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.80.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1 Computational Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.81.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.82.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2 Chain Rule of Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.83.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.84.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.85.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3 Recursively Applying the Chain Rule to Obtain Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.86.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.87.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.88.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.89.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.90.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.4 Back-Propagation Computation in Fully-Connected MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.91.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.5 Symbol-to-Symbol Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.92.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.93.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.94.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.95.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.96.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.6 General Back-Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.97.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.98.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.99.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.100.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.101.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.7 Example: Back-Propagation for MLP Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.102.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.103.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.8 Complications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.9 Diﬀerentiation outside the Deep Learning Community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.104.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.105.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.10 Higher-Order Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.106.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.6 Historical Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료\n",
    "* [1] DEEP LEARNING (Yoshua Bengio)- http://www.deeplearningbook.org/\n",
    "* [2] L1 : From Machine Learning to Deep Learning (Udacity) -  https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63\n",
    "* [3] L1 : Deep Neural Networks (Udacity) https://drive.google.com/file/d/0B3vuuoFuJsKWdFFkMS10N1BpLTg/view\n",
    "* [4] CS231n: Convolutional Neural Networks for Visual Recognition : Image classification and the data-driven approach & k-nearest neighbor & Linear classification I - http://cs231n.stanford.edu/slides/winter1516_lecture2.pdf\n",
    "* [5] CS231n: Convolutional Neural Networks for Visual Recognition : Linear classification II & Higher-level representations, image features & Optimization, stochastic gradient descent - http://cs231n.stanford.edu/slides/winter1516_lecture3.pdf\n",
    "* [6] CS231n: Convolutional Neural Networks for Visual Recognition : Backpropagation & Introduction to neural networks - http://cs231n.stanford.edu/slides/winter1516_lecture4.pdf\n",
    "* [7] Convex analysis - https://msampler.wordpress.com/2009/07/08/convex-analysis/\n",
    "* [8] Affie Transformation - https://en.wikipedia.org/wiki/Affine_transformation\n",
    "* [9] Mixture Density Networks with TensorFlow - http://blog.otoro.net/2015/11/24/mixture-density-networks-with-tensorflow/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
