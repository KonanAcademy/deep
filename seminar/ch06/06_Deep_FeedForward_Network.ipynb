{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 Deep Feedfowrd Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 딥러닝 세미나 : 이론 [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* 6.1 Example: Learning XOR\n",
    "* 6.2 Gradient-Based Learning\n",
    "    - 6.2.1 Cost Functions\n",
    "        - 6.2.1.1 Learning Conditional Distributions with Maximum Likelihood\n",
    "        - 6.2.1.2 Learning Conditional Statistics \n",
    "    - 6.2.2 Output Units\n",
    "        - 6.2.2.1 Linear Units for Gaussian Output Distributions\n",
    "        - 6.2.2.2 Sigmoid Units for Bernoulli Output Distributions\n",
    "        - 6.2.2.3 Softmax Units for Multinoulli Output Distributions\n",
    "        - 6.2.2.4 Other Output Types\n",
    "* 6.3 Hidden Units\n",
    "    - 6.3.1 Rectiﬁed Linear Units and Their Generalizations\n",
    "    - 6.3.2 Logistic Sigmoid and Hyperbolic Tangent\n",
    "    - 6.3.3 Other Hidden Units\n",
    "* 6.4 Architecture Design\n",
    "    - 6.4.1 Universal Approximation Properties and Depth\n",
    "    - 6.4.2 Other Architectural Considerations\n",
    "* 6.5 Back-Propagation and Other Diﬀerentiation Algorithms\n",
    "    - 6.5.1 Computational Graphs\n",
    "    - 6.5.2 Chain Rule of Calculus\n",
    "    - 6.5.3 Recursively Applying the Chain Rule to Obtain Backprop\n",
    "    - 6.5.4 Back-Propagation Computation in Fully-Connected MLP\n",
    "    - 6.5.5 Symbol-to-Symbol Derivatives\n",
    "    - 6.5.6 General Back-Propagation\n",
    "    - 6.5.7 Example: Back-Propagation for MLP Training\n",
    "    - 6.5.8 Complications\n",
    "    - 6.5.9 Diﬀerentiation outside the Deep Learning Community\n",
    "    - 6.5.10 Higher-Order Derivatives\n",
    "* 6.6 Historical Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [2] L1 : From Machine Learning to Deep Learning (Udacity) -  https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63\n",
    "* [3] L1 : Deep Neural Networks (Udacity) https://drive.google.com/file/d/0B3vuuoFuJsKWdFFkMS10N1BpLTg/view\n",
    "* [4] CS231n: Convolutional Neural Networks for Visual Recognition : Image classification and the data-driven approach & k-nearest neighbor & Linear classification I - http://cs231n.stanford.edu/slides/winter1516_lecture2.pdf\n",
    "* [5] CS231n: Convolutional Neural Networks for Visual Recognition : Linear classification II & Higher-level representations, image features & Optimization, stochastic gradient descent - http://cs231n.stanford.edu/slides/winter1516_lecture3.pdf\n",
    "* [6] CS231n: Convolutional Neural Networks for Visual Recognition : Backpropagation & Introduction to neural networks - http://cs231n.stanford.edu/slides/winter1516_lecture4.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models are called feedforward because information ﬂows through thefunction being evaluated from x, through the intermediate computations used to deﬁne f, and ﬁnally to the output y. \n",
    "* There are no feedback connections in whichoutputs of the model are feedback into itself. \n",
    "* When feedforward neural networksare extended to include feedback connections, they are called recurrent neuralnetworks, presented in Chapter 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedforward neural networks are called networks because they are typically represented by composing together many diﬀerent functions.\n",
    "* The model is associatedwith a directed acyclic graph describing how the functions are composed together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, \n",
    "* we might have three functions $f^{(1)}$, $f^{(2)}$, and $f^{(3)}$ connected in a chain, to form f(x) = $f^{(3)}(f^{(2)}(f^{(1)}(x)))$.\n",
    "* $f^{(1)}$ is called the ﬁrst layer of the network, $f^{(2)}$ is called the second layer, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall length of the chain gives the depth of the model. \n",
    "* It is from this terminology that the name “deep learning” arises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ﬁnal layer of a feedforward network is called the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During neural network training, we drive f(x) to match $f^∗(x)$. \n",
    "* The training data provides us with noisy, approximate examples of $f^∗(x)$ evaluated at diﬀerent training points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each examplexis accompanied by a label $y ≈ f^∗(x)$.\n",
    "* The training examples specify directly what the output layer must do at each point x; \n",
    "* it must produce a value that is close to y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning algorithm must decidehow to use those layers to produce the desired output, but the training data does not say what each individual layer should do. * Instead, the learning algorithm mustdecide how to use these layers to best implement an approximation of $f^∗$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because the training data does not show the desired output for each of these layers, these layers are called hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, these networks are called neural because they are loosely inspired by neuroscience. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The goal of modern neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, modern neural network research is guided by many mathematical and engineering disciplines, and the goal of neural networks is not to perfectly model the brain. \n",
    "* It is best to think of feedforward networks as function approximation machines that are designed to achieve statistical generalization, occasionally drawing some insights from what we know about the brain, rather than as models of brain function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to understand feedforward networks is to begin with linear models and consider how to overcome their limitations. \n",
    "* Linear models, such as logistic regression and linear regression, are appealing because they may be ﬁt eﬃciently and reliably, either in closed form or with convex optimization. \n",
    "* Linear models also have the obvious defect that the model capacity is limited to linear functions, so the model cannot understand the interaction between any two input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nonlinear transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extend linear models to represent nonlinear functions of x, we can apply the linear model not to x itself but to a transformed input φ(x), where φis a nonlinear transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The question is then how to choose the mapping φ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.One option is to use a very generic φ, such as the inﬁnite-dimensional φ that is implicitly used by kernel machines based on the RBF kernel. \n",
    "* If φ(x) is of high enough dimension, we can always have enough capacity to ﬁt thetraining set, but generalization to the test set often remains poor. \n",
    "* Very generic feature mappings are usually based only on the principle of local smoothness and do not encode enough prior information to solve advanced problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Another option is to manually engineer φ.\n",
    "* Until the advent of deep learning, this was the dominant approach. \n",
    "* This approach requires decades of human eﬀort for each separate task, with practitioners specializing in diﬀerent domains such as speech recognition or computer vision, and with little transfer between domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.The strategy of deep learning is to learn φ. \n",
    "* In this approach, we have a model y = f(x;θ,w) = $φ(x;θ)^{\\top}w$. \n",
    "* We now have parameters θ that we use to learn φ from a broad class of functions, and parameters w that map from φ(x) to the desired output. \n",
    "* This is an example of a deep feedforward network, with φ deﬁning a hidden layer. \n",
    "* This approach is the only one of the three that gives up on the convexity of the training problem, but the beneﬁts outweigh the harms. \n",
    "* In this approach, we parametrize the representation as φ(x;θ) and use the optimization algorithm to ﬁnd the θ that corresponds to a good representation. \n",
    "* If we wish, this approach can capture the beneﬁt of the ﬁrst approach by being highly generic—we do so by using a very broad family φ(x;θ). \n",
    "* This approach can also capture the beneﬁt of the second approach.\n",
    "* Human practitioners can encode their knowledge to help generalization by designing families φ(x;θ) that they expect will perform well. \n",
    "* The advantage is that the human designer only needs to ﬁnd the right general function family rather than ﬁnding precisely the right function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Example: Learning XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XOR function (“exclusive or”) is an operation on two binary values,x1 and x2. When exactly one of these binary values is equal to 1, the XOR function returns 1. Otherwise, it returns 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can treat this problem as a regression problem and use a mean squared error loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Linear_least_squares_example2.svg/500px-Linear_least_squares_example2.svg.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example, we will not be concerned with statistical generalization.We want our network to perform correctly on the four points X={ $[0,0]^{\\top}$,  $[0,1]^{\\top}$, $[1,0]^{\\top}$, and $[1,1]^{\\top}$}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After solving the normal equations, we obtain w=0 and b=1/2. The linear model simply outputs 0.5 everywhere. Why does this happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speciﬁcally, we will introduce a very simple feedforward network with onehidden layer containing two hidden units. See Fig. 6.2 for an illustration of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f^{(1)}(x;W,c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h=^{f(1)}(x;W,c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y=f^{(2)}(h;w,b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(x;W,c,w,b) = $f^{(2)}(f^{(1)}(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f^{(1)}(x)=W^{\\top}x$ and $f^{(2)}(h)=h^{\\top}w$. Then $f(x)=w^{\\top}W^{\\top}x$. We could represent this function as f(x) = $x^{\\top}w^{\\prime}$ where $w^{\\prime}= Ww$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h=g(W^{\\top}x+c)$,where W provides the weights of a linear transformation and c the biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation functiong is typically chosen to be a function that is applied element-wise, with $h_{i}=g(x^{\\top}W:,_{i}+c_{i})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rectiﬁed linear unit or ReLU\n",
    "g(z) = max{0, z}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this example, we simply speciﬁed the solution, then showed that it obtained zero error. \n",
    "* In a real situation, there might be billions of model parameters and billions of training examples, so one cannot simply guess the solution as we did here. \n",
    "* <font color=\"red\">Instead, a gradient-based optimization algorithm can ﬁnd parameters thatproduce very little error.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Gradient-Based Learning\n",
    "* 6.2.1 Cost Functions\n",
    "* 6.2.2 Output Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Designing and training a neural network is not much diﬀerent from training any other machine learning model with gradient descent.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://qph.is.quoracdn.net/main-qimg-46a77c77c721ba34283308232a1788c8?convert_to_webp=true\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">The largest diﬀerence between the linear models we have seen so far and neural networks is that the nonlinearity of a neural network causes most interesting loss functions to become non-convex.  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [7] Convex analysis - https://msampler.wordpress.com/2009/07/08/convex-analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://msampler.files.wordpress.com/2009/07/cvx-fun.gif\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stocastic gradient decent VS others(linear equation solver, convex optimization) \n",
    "* This means that neural networks are usually trained by using iterative, gradient-based optimizers that merely <font color=\"red\">drive the cost function to a very low value</font>, rather than the linear equation solvers used to train linear regression models or the convex optimization algorithms with global convergence guarantees used to train logistic regression or SVMs.\n",
    "* Convex optimization converges starting from any initial parameters (in theory—in practice it is very robust but can encounter numerical problems). \n",
    "* Stochastic gradient descent appliedto non-convex loss functions has <font color=\"red\">no such convergence guarantee</font>, and is <font color=\"red\">sensitive to the values of the initial parameters</font>.\n",
    "* <font color=\"blue\">For feedforward neural networks, it is important to initialize all weights to small random values. The biases may be initialized to zero or to small positive values.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://camo.githubusercontent.com/30bf2d42d3a9b0e07dbc03a014f4e36dbc06904f/68747470733a2f2f7261772e6769746875622e636f6d2f7175696e6e6c69752f4d616368696e654c6561726e696e672f6d61737465722f696d61676573466f724578706c616e6174696f6e2f4772616469656e7444657363656e74576974684d75746c69706c654c6f63616c4d696e696d756d2e6a7067\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.holehouse.org/mlclass/17_Large_Scale_Machine_Learning_files/Image%20[16].png\"   />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://43284bdcf41602d9ee3b7f9155623bc4db1a5d55.googledrive.com/host/0B56ak7W-HmqASVBYZTJ1WXVoQUU/img/stochastic.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.slidesharecdn.com/nn-150216124050-conversion-gate01/95/neural-networks-overview-11-638.jpg?cb=1424102465\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can of course, train models such as linear regression and support vector machines with gradient descent too, and in fact this is <font color=\"red\">common when the trainingset is extremely large.</font>\n",
    "* From this point of view, training a neural network is notmuch diﬀerent from training any other model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with other machine learning models, <font color=\"red\">to apply gradient-based learning</font> we must choose a <font color=\"blue\">cost function</font>, and we must choose how to <font color=\"blue\">represent the output of the model</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total cost function used to train a neural network will often combine one of the primary cost functions described here with a <font color=\"red\">regularization term</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.1 Cost Functions\n",
    "* 6.2.1.1 Learning Conditional Distributions with Maximum Likelihood\n",
    "* 6.2.1.2 Learning Conditional Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important aspect of the design of a deep neural network is the <font color=\"red\">choice of the cost function</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### priciple of of maximum likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(y | x;θ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In most cases, our <font color=\"red\">parametric model</font> deﬁnes a distributionp(y|x;θ) and we simply use the <font color=\"blue\">principle of maximum likelihood</font>. \n",
    "* This means we use the <font color=\"red\">cross-entropy</font> <font color=\"blue\">between the training data and the model’s predictions</font> as the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://statgen.iop.kcl.ac.uk/media/ml1.gif\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Mplwp_shannon_entropy.svg/2000px-Mplwp_shannon_entropy.svg.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://colah.github.io/posts/2015-09-Visual-Information/img/CrossEntropyDef.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/math/5/7/9/57915b0c4d0e62a602db5e757742b1d3.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cfile4.uf.tistory.com/image/2645033951991C20193341\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63/res/1ff6f90c-d594-468b-86a2-d70289958ce8.png?resizeSmall&width=832\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.slidesharecdn.com/215implementingdeeplearningusingcudnn-150915052020-lva1-app6892/95/251-implementing-deep-learning-using-cu-dnn-17-638.jpg?cb=1442295596\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/svmvssoftmax.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://images.slideplayer.com/11/3277991/slides/slide_57.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://qph.is.quoracdn.net/main-qimg-9e2d012ef7cb8b29d2bed14d2975c986?convert_to_webp=true\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://qiita-image-store.s3.amazonaws.com/0/100523/195fb6d9-adf6-9166-5c81-08665777032d.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://2.bp.blogspot.com/-EVROdmAZ0No/VoTHrtrREZI/AAAAAAAAAn0/gyKG0BUjst8/s1600/softmax-regression-scalargraph.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63/res/d6f7961c-b05d-495d-af14-4d6a21feecdf.png?resizeSmall&width=832\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1.1 Learning Conditional Distributions with Maximum Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://statgen.iop.kcl.ac.uk/media/ml2.gif\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63/res/d6f7961c-b05d-495d-af14-4d6a21feecdf.png?resizeSmall&width=832\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most modern neural networks are trained using maximum likelihood. This means that the cost function is simply the <font color=\"red\">negative log-likelihood</font>, <font color=\"blue\">equivalently described as the cross-entropy between the training data and the model distribution</font>. This cost function is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speciﬁc form of the cost function changes from model to model, dependingon the speciﬁc form of $log p_{model}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if $p_{model}(y|x) = N(y;f(x;θ),I)$,then we recover the mean squared error cost,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "up to a scaling factor of $\\frac{1}{2}$ and a term that does not depend on θ. The discarded constant is based on the variance of the Gaussian distribution, which in this casewe chose not to parametrize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we saw that the equivalence between maximum likelihood estimation with an output distribution and minimization of mean squared error holds for a linear model, but in fact, the equivalence holds regardless of the f(x; θ) used to predict the mean of the Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">An advantage of this approach of deriving the cost function from maximum likelihood is that it removes the burden of designing cost functions for each model</font>.  Specifying a model $p(y|x)$ automatically determines a cost function $logp(y|x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">One recurring theme throughout neural network design is that the gradient ofthe cost function must be large and predictable enough to serve as a good guidefor the learning algorithm.</font>\n",
    "* Functions that saturate (become very ﬂat) undermine this objective because they make the gradient become very small. \n",
    "* In many cases this happens because the activation functions used to produce the output of thehidden units or the output units saturate.\n",
    "* <font color=\"red\">The negative log-likelihood helps to avoid this problem for many models</font>. \n",
    "    - Many output units involve an exp function that can saturate when its argument is very negative.\n",
    "    - The log function in the negative log-likelihood cost function undoes the exp of some output units. \n",
    "    - We will discuss the interaction between the cost function and the choice of output unit inSec. 6.2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">One unusual property of the cross-entropy cost used to perform maximum likelihood estimation</font> is that it usually does not have a minimum value when applied to the models commonly used in practice.\n",
    "* <font color=\"blue\">For discrete output variables</font>, most models are parametrized in such a way that they <font color=\"blue\">cannot represent a probability of zero or one, but can come arbitrarily close to doing so</font>. Logistic regressionis an example of such a model.\n",
    "* <font color=\"red\">For real-valued output variables</font>, if the model can control the <font color=\"red\">density of the output distribution</font> (for example, by learning the variance parameter of a Gaussian output distribution) then it <font color=\"red\">becomes possible to assign extremely high density</font> to the correct training set outputs, resulting <font color=\"red\">in cross-entropy approaching negative inﬁnity</font>.\n",
    "* <font color=\"blue\">Regularization techniques</font> described in Chapter 7 provide several diﬀerent ways of modifying the learning problem sothat the model cannot reap unlimited reward in this way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1.2 Learning Conditional Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.mwclearning.com/wp-content/uploads/2011/04/conditionalProb.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.cvlibs.net/projects/gausspro/gausspro02.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of learning a full probability distribution p(y|x;θ) we often want to learn just one conditional statistic of y given x.\n",
    "* For example, we may have a predictor f(x;θ) that we wish to predict the mean of y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">If we use a suﬃciently powerful neural network</font>, <font color=\"blue\">we can think of the neural network as being able to represent any function $f$ from a wide class of functions</font>, with this class being limited only by features such as continuity and boundedness rather than by having a speciﬁc parametric form.\n",
    "* From this point of view, <font color=\"blue\">we can view the cost function as being a functional</font> rather than just a function. \n",
    "    - A functional is a mapping from functions to real numbers.\n",
    "* <font color=\"red\">We can thus think of learning as choosing a function rather than merely choosing a set of parameters</font>.\n",
    "* <font color=\"blue\">We can design our cost functional to have its minimum occur at some speciﬁcfunction we desire.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculus of variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving an <font color=\"red\">optimization problem with respect to a function</font> requires a mathematical tool called calculus of variations, described in Sec. 19.4.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculus of variations may be used to derive the following two results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* so long as this function lies within the class we optimize over. \n",
    "* In other words, if we could train on inﬁnitely many samples from the true data-generating distribution, minimizing the mean squared error cost function gives a function that predicts the mean of y for each value of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, <font color=\"red\">mean squared error and mean absolute error often lead to poor results when used with gradient-based optimization</font>. \n",
    "* Some output units that saturate produce very small \n",
    "* <font color=\"blue\">This is one reason that the cross-entropy cost function is more popular</font> than mean squared error or mean absolute error, even when it is not necessary to estimate an entire distribution p(y|x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.2 Output Units\n",
    "* 6.2.2.1 Linear Units for Gaussian Output Distributions\n",
    "* 6.2.2.2 Sigmoid Units for Bernoulli Output Distributions\n",
    "* 6.2.2.3 Softmax Units for Multinoulli Output Distributions\n",
    "* 6.2.2.4 Other Output Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/nn1/neuron_model.jpeg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">The choice of cost function is tightly coupled with the choice of output unit</font>\n",
    "* Most of the time, we simply use the cross-entropy between the data distribution and the model distribution. \n",
    "* <font color=\"blue\">The choice of how to represent the output then determines the form of the cross-entropy function</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this section, we suppose that the feedforward network provides a set of hidden features deﬁned by h=f(x;θ). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The role of the output layer is then to provide some additional transformation from the features to complete the task that the network must perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2.1 Linear Units for Gaussian Output Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [8] Affie Transformation - https://en.wikipedia.org/wiki/Affine_transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.publiclab.org/system/images/photos/000/004/507/original/geometric-transformations.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/350px-Normal_Distribution_PDF.svg.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple kind of output unit is an output unit based on an <font color=\"red\">aﬃne transformation with no nonlinearity</font>. These are often just called linear units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.13.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximizing the log-likelihood is then equivalent to minimizing the mean squared error\n",
    "* The maximum likelihood framework \n",
    "    - makes it straight forward to learn the covariance of the Gaussian too, or \n",
    "    - to make the covariance of the Gaussian be a function of the input. \n",
    "    - However, the covariance must be constrained to be a positive deﬁnite matrix for all inputs. \n",
    "    - It is diﬃcult to satisfy such constraints with a linear output layer, so typically other output units are used to parametrize the covariance.\n",
    "    - Approaches to modeling the covariance are described shortly, in Sec. 6.2.2.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2.2 Sigmoid Units for Bernoulli Output Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://artint.info/figures/ch07/sigmoidc.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://chi.se.wtb.tue.nl/_images/binomial.svg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many tasks require <font color=\"red\">predicting the value of a binary variable y</font>. Classiﬁcation problems with <font color=\"blue\">two classes</font> can be cast in this form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A Bernoulli distribution is deﬁned by just a single number. \n",
    "* The neural net needs to predict only $P(y=1|x)$.\n",
    "* For this number to be a valid probability, itmust lie in the interval [0, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear unit case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wereto use a linear unit, and threshold its value to obtain a valid probability:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.14.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This would indeed deﬁne a valid conditional distribution, but we would <font color=\"red\">not be able to train it very eﬀectively with gradient descent</font>. \n",
    "* Any time that $w^{\\top}h+b$ strayed outside the unit interval, <font color=\"blue\">the gradient of the output of the model with respect to its parameters would be 0</font>. \n",
    "* <font color=\"red\">A gradient of 0 is typically problematic</font> because the learning algorithm <font color=\"red\">no longer has a guide for how to improve the corresponding parameters</font>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://nbviewer.jupyter.org/github/psygrammer/qgm/blob/master/part3/connectionist/ch01/figures/cap1.11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid output unit case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sigmoid output unit is deﬁned by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.15.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where σ is the logistic sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of the sigmoid output unit as having two components. \n",
    "* First, ituses a linear layer to compute $z=w^{\\top}h+b$.\n",
    "* Next, it <font color=\"red\">uses the sigmoid activation function to convert z into a probability</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid can be motivated by constructing an unnormalized probability distribution $P^\\sim(y)$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/svmvssoftmax.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://oakmachine.com/img/multinomial-logistic-classification-diagram.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nomarlizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then divide by an appropriate constant to obtain a valid probability distribution. If we begin with the assumption that the unnormalized log probabilities are linear inyandz, we can exponentiate to obtain the unnormalized probabilities. We then normalize to see that this <font color=\"red\">yields a Bernoulli distribution controlled by a sigmoidal transformation of z</font>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.16.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Probability distributions based on exponentiation and normalization are commonthroughout the statistical modeling literature. \n",
    "* The z variable deﬁning such a distribution over binary variables is called a <font color=\"red\">logit</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach to predicting the probabilities in log-space is natural to use with maximum likelihood learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the cost function used with maximum likelihood is −log P(y | x), the login the cost function undoes the exp of the sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color=\"red\">The loss function</font> for maximum likelihood learning of a <font color=\"red\">Bernoulli parametrized by a sigmoid</font> is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.17.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* y rewriting the loss in terms of the softplus function, we can see that it <font color=\"red\">saturates only when (1−2y)z is very negative</font>.\n",
    "* Saturation thus occurs only \n",
    "    - when the model already has the right answer — when \n",
    "        - y = 1 and z is very positive, or\n",
    "        - y = 0 and z is very negative. \n",
    "* When z has the wrong sign, the argument to the softplus function, (1−2y)z, may be simpliﬁed to|z|. \n",
    "    - As |z| becomes large while z has the wrong sign, \n",
    "        - the softplus function asymptotes toward simply returning its argument |z|. \n",
    "     - The derivative with respect to z asymptotes to sign(z), so, in the limit of extremely incorrect z, \n",
    "         - the softplus function does not shrink the gradient at all. \n",
    "             - <font color=\"red\">This property is very useful because it means that gradient-based learning can act to quickly correct a mistaken z</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고 : Softpuls function\n",
    "ReLU can be approximated by a so called softplus function (for which the derivative is the logistic functions):\n",
    "\n",
    "g(x) = log(1+exp(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://imiloainf.files.wordpress.com/2013/11/activation_funcs1.png\" with=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other loss functions\n",
    "* When we use other loss functions such as \n",
    "    - mean squared error, \n",
    "        - the loss can saturate anytime σ(z) saturates. \n",
    "* The sigmoid activation function saturates to 0 \n",
    "    - when z becomes very negative and saturates to 1\n",
    "    - when z becomes very positive.\n",
    "    - The gradient can shrink too small to be useful for learning \n",
    "        - whenever this happens, \n",
    "        - whether the model has the correct answer or the incorrect answer. \n",
    "* <font color=\"red\">For this reason, maximum likelihood is almost always the preferred approach to training sigmoid output units</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### negative log-likelihood\n",
    "* Analytically, the logarithm of the sigmoid is always deﬁned and ﬁnite, \n",
    "    - because the sigmoid returns values restricted to the open interval (0,1), \n",
    "        - rather than using the entire closed interval of valid probabilities [0,1]. \n",
    "* In software implementations,to avoid numerical problems,\n",
    "    - it is <font color=\"red\">best to write the negative log-likelihood as a function of z</font>, \n",
    "        - rather than as a function of $\\hat{y}=σ(z)$. \n",
    "             - If the sigmoid function underﬂows to zero, then taking the logarithm of $\\hat{y}$ yields negative inﬁnity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2.3 Softmax Units for Multinoulli Output Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/math/0/9/9/0991837b7d5a522ebc156f51dadbed0e.png\" />\n",
    "<img src=\"https://qph.cr.quoracdn.net/main-qimg-9e2d012ef7cb8b29d2bed14d2975c986\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/math/4/7/f/47f3344c0d641fa910088ca66cd1ecf8.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.slidesharecdn.com/machinelearningmeetup-12-18-2013-140115184408-phpapp01/95/digging-into-the-dirichlet-distribution-by-max-sklar-11-638.jpg?cb=1389811694\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.mathworks.com/help/stats/multinomial_plot2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any time we wish to represent a probability distribution over a <font color=\"red\">discrete variable with n possible values</font>, we may <font color=\"blue\">use the softmax function</font>. \n",
    "* This can be seen as a <font color=\"red\">generalization of the sigmoid function</font> which was used to represent a probability distribution over a binary variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/svmvssoftmax.png\" width=600 />\n",
    "<img src=\"http://oakmachine.com/img/multinomial-logistic-classification-diagram.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### binary case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of binary variables, we wished to produce a single number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.18.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this number needed to lie between 0 and 1, and because we wanted thelogarithm of the number to be well-behaved for gradient-based optimization ofthe log-likelihood, we chose to instead predict a number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.19.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exponentiating and normalizing gave us a Bernoulli distribution controlled by the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">To generalize to the case of a discrete variable with n values</font>, we now need to produce a vector $\\hat{y}$, with $\\hat{y}_{i}=P(y=i|x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same approach that worked for the Bernoulli distribution generalizes to the multinoulli distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a linear layer predicts unnormalized log probabilities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.20.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.21.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The <font color=\"red\">ﬁrst term</font> of Eq. 6.30 shows that the input $z_{i}$ always has a <font color=\"red\">direct contribution to the cost function</font>.\n",
    "    - Because this term cannot saturate, we know that learning can proceed, even if the contribution of $z_{i}$ to the second term of Eq. 6.30 becomes very small.\n",
    "    - When maximizing the log-likelihood, the ﬁrst term encourages $z_{i}$ to be pushed up, while the second term encourages all of z to be pushed down.\n",
    "* The intuition, for <font color=\"blue\">the second term</font>, we can gain from this approximation is that the negative log-likelihood cost function always <font color=\"blue\">strongly penalizes the most active incorrect prediction</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unregularized maximum likelihood case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, unregularized maximum likelihood will drive the model to learn parameters that drive the softmax to predict the fraction of counts of each outcome observed in the training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.22.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because maximum likelihood is a consistent estimator, this is <font color=\"blue\">guaranteed to happen so long as the model family is capable of representing the training distribution</font>. \n",
    "* In practice, <font color=\"red\">limited model capacity and imperfect optimization</font> will mean that <font color=\"red\">the model is only able to approximate these fractions</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other objective functions \n",
    "<font color=\"red\">Many objective functions other than the log-likelihood do not work as well with the softmax function</font>. \n",
    "* Speciﬁcally, <font color=\"blue\">objective functions that do not use a log to undo the exp of the softmax fail to learn</font> when the argument to the exp becomes very negative, <font color=\"blue\">causing the gradient to vanish</font>. \n",
    "* In particular, <font color=\"red\">squared error is a poor loss function for softmax units, and can fail to train</font> the model to change its output, even when the model makes highly conﬁdent incorrect predictions (Bridle,1990). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">To understand why these other loss functions can fail, we need to examine the softmax function itself</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### examine the softmax function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/math/0/9/9/0991837b7d5a522ebc156f51dadbed0e.png\" />\n",
    "<img src=\"https://qph.cr.quoracdn.net/main-qimg-9e2d012ef7cb8b29d2bed14d2975c986\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Like the sigmoid, the softmax activation can saturate</font>\n",
    "* In the case of the softmax, there are multiple output values. These output values can saturate <font color=\"red\">when the diﬀerences between input values become extreme</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see that the softmax function responds to the diﬀerence between its inputs,observe that the <font color=\"blue\">softmax output is invariant to adding the same scalar to all of its inputs</font>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.23.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this property, we can derive a numerically stable variant of the softmax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.24.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The reformulated version allows us to evaluate <font color=\"red\">softmax with only small numerical errors</font> even <font color=\"blue\">when z contains extremely large or extremely negative numbers</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2.4 Other Output Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"blue\">The linear, sigmoid, and softmax output units</font> described above are the <font color=\"blue\">most common</font>. \n",
    "* Neural networks can generalize to almost <font color=\"red\">any kind of output layer that we wish</font>.\n",
    "* <font color=\"red\">The principle of maximum likelihood provides a guide for how to design</font> a good cost function for nearly any kind of output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we define a conditional distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.25.png\" width=100/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the principle of maximum likelihood suggests we use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.26.png\" width=200 /> as our cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### neural network as representing a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we can think of the neural network as representing a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.27.png\" width=100 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of this function are not direct predictions of the value y. Instead, $f(x;θ)=ω$ provides the parameters for a distribution over y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our loss functioncan then be interpreted as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.29.png\" width=200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example : we may wish to learn the variance of a conditional Gaussian for y, given x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.cvlibs.net/projects/gausspro/gausspro02.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the simple case,\n",
    "    <img src=\"http://hyperphysics.phy-astr.gsu.edu/hbase/math/immath/gauds.gif\" width=300 />\n",
    "    - where the variance $σ^{2}$ is a constant, \n",
    "    - there is a closed form expression \n",
    "        - because the maximum likelihood estimator of variance is simply the empirical mean of the squared diﬀerence \n",
    "            - between observations y and their expected value. \n",
    "    - A computationally more expensive approach that \n",
    "        - does not require writing special-case code \n",
    "        - is to simply include the variance \n",
    "            - as one of the properties of the distribution \n",
    "                - $p(y | x)$ that is controlled by \n",
    "                    - $ω=f(x;θ)$. \n",
    "    - The negative log-likelihood \n",
    "        - $−log p(y;ω(x))$ \n",
    "        - will then provide a cost function \n",
    "            - with the appropriate terms necessary \n",
    "                - to make our optimization procedure incrementally learn the variance. \n",
    "* In the simple case \n",
    "    - where the standard deviation does not depend on the input, \n",
    "    - we can make a new parameter in the network that \n",
    "        - is copied directly into ω. \n",
    "    - This new parameter \n",
    "        - might be $σ$ itself or \n",
    "        - could be a parameter $v$ representing $σ^{2}$ or \n",
    "        - it could be a parameter β representing $1/σ^{2}$, \n",
    "        - depending on how we choose to parametrize the distribution. \n",
    "* We may wish our model to predict \n",
    "    - a diﬀerent amount of variance in y \n",
    "        - for diﬀerent values of x. \n",
    "    - This is called a heteroscedastic model. \n",
    "        <img src=\"http://gerardnico.com/wiki/_media/statistics/heteroscedasticity.jpg\" width=400 />\n",
    "    - In the heteroscedastic case, \n",
    "        - we simply make \n",
    "            - the speciﬁcation of the variance \n",
    "                - be one of the values output by $f(x;θ)$. \n",
    "            - A typical way to do this is to formulate \n",
    "                - the Gaussian distribution \n",
    "                    - using precision, \n",
    "                        - rather than variance, as described in Eq.3.22.\n",
    "                        <img src=\"figures/eq3.22.png\" width=400 />\n",
    "                        <img src=\"http://www.paulbays.com/code/JV10/fig2.gif\" width=300 />\n",
    "* In the multivariate case\n",
    "    <img src=\"http://i.stack.imgur.com/qqG5Y.png\" width=300 />\n",
    "    - it is most common to use a diagonal precision matrix\n",
    "        <img src=\"figures/cap6.37.png\" width=400 />\n",
    "    - This formulation works well with gradient descent \n",
    "        - because the formula for the log-likelihood of the Gaussian distribution \n",
    "            - parametrized by $β$ involves only \n",
    "                - multiplication by $β_{i}$ and \n",
    "                - addition of log $β_{i}$. \n",
    "            - The gradient of \n",
    "                - multiplication, \n",
    "                - addition, and \n",
    "                - logarithm operations \n",
    "            - is well-behaved. \n",
    "    - By comparison, \n",
    "        - if we parametrized theoutput in terms of variance,\n",
    "            - we would need to use division. \n",
    "                - The division function becomes arbitrarily steep near zero.\n",
    "            - While large gradients can help learning,\n",
    "                - arbitrarily large gradients usually result in instability. \n",
    "        - If we parametrized theoutput in terms of standard deviation,\n",
    "            - the log-likelihood would still involve division, and would also involve squaring. \n",
    "            - The gradient through the squaring operation can vanish near zero, making it diﬃcult to learn parameters that are squared.\n",
    "    - Regardless of whether we use standard deviation, variance, or precision, we must ensure that \n",
    "        - the covariance matrix of the Gaussian is positive deﬁnite.\n",
    "            - Becausethe eigenvalues of the precision matrix are the reciprocals of the eigenvalues of the covariance matrix, \n",
    "            - this is equivalent to ensuring that the precision matrix is positive deﬁnite. \n",
    "        - If we use \n",
    "            - a diagonal matrix, or \n",
    "            - a scalar times the diagonal matrix,\n",
    "        - then the only condition we need to enforce on the output of the model is positivity.\n",
    "* If we suppose that \n",
    "    - $a$ is the raw activation of the model\n",
    "        - used to determine the diagonal precision, \n",
    "    - we can use \n",
    "        - the softplus function \n",
    "            - to obtain a positive precision vector :\n",
    "            <img src=\"figures/cap6.42.png\" width=100 />\n",
    "* This same strategy applies equally if using variance or standard deviation rather than precision or if using a scalar times identity rather than diagonal matrix.\n",
    "    - softpuls : g(x) = log(1+exp(x))\n",
    "    <img src=\"https://imiloainf.files.wordpress.com/2013/11/activation_funcs1.png\" with=300 />\n",
    "* It is rare to learn a covariance or precision matrix with richer structure than diagonal.\n",
    "    - If the covariance is full and conditional, \n",
    "        - then a parametrization must be chosen \n",
    "            - that guarantees positive-deﬁniteness of \n",
    "                - the predicted covariance matrix.\n",
    "        - This can be achieved by writing\n",
    "            <img src=\"figures/cap6.43.png\" width=300 />\n",
    "            where $B$ is an unconstrained square matrix.\n",
    "        - One practical issue if the matrix is full rank is that computing the likelihood is expensive, with\n",
    "            <img src=\"figures/cap6.45.png\" width=300 />\n",
    "        - computation for the determinant and \n",
    "            <img src=\"figures/cap6.46.png\" width=200 />\n",
    "        - (or equivalently, and more commonly done, its eigendecomposition or that of $B(x)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example : multimodal regression = Neural networks with Gaussian mixtures = mixture density networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We often want to perform multimodal regression, that is, \n",
    "    - to predict real values that \n",
    "        - come from  a conditional distributionp $(y|x)$ that can have\n",
    "            - several diﬀerent peaks in $y$ space for \n",
    "                - the same value of $x$. \n",
    "* In this case, a Gaussian mixture is a natural representation for the output\n",
    "    <img src=\"http://courses.ee.sun.ac.za/Pattern_Recognition_813/lectures/lecture06/img2.png\" width=300 />\n",
    "* Neural networks with Gaussian mixtures as their output are often called mixture density networks.\n",
    "    ##### 참고\n",
    "    * [9] Mixture Density Networks with TensorFlow - http://blog.otoro.net/2015/11/24/mixture-density-networks-with-tensorflow/\n",
    "* A Gaussian mixture output with $n$ components is deﬁned by the conditional probability distribution\n",
    "    <img src=\"figures/cap6.48.png\" width=400 />\n",
    "<img src=\"figures/cap6.49.png\" width=600 />\n",
    "    - 1.Mixture components $p(c=i|x)$: \n",
    "        - these form a multinoulli distribution over the $n$ diﬀerent components associated with latent variable $c$, \n",
    "        - and can typically be obtained by a softmax over an n-dimensional vector, \n",
    "            - to guarantee that these outputs are positive and sum to 1\n",
    "    - 2.<img src=\"figures/cap6.51.png\" width=200 />\n",
    "        - these indicate the center or mean associated with the i-th Gaussian component, and are unconstrained (typically with no nonlinearity at all for these output units).\n",
    "    - 3.<img src=\"figures/cap6.52.png\" width=200 /> \n",
    "        -  these specify the covariance matrix for each component $i$. \n",
    "        - As when learning a single Gaussian component, we typically use a diagonal matrix to avoid needing to compute determinants.\n",
    "* It has been reported that gradient-based optimization of conditional Gaussian mixtures (on the output of neural networks) \n",
    "    - can be unreliable, \n",
    "    - in part because one gets divisions (by the variance) \n",
    "        - which can be numerically unstable \n",
    "            - (when some variance gets to be small for a particular example, yielding very large gradients).\n",
    "    - One solution is to \n",
    "        - clip gradients (see Sec. 10.11.1) \n",
    "            - while another is to scale the gradients heuristically\n",
    "* Gaussian mixture outputs are particularly eﬀective \n",
    "    - in generative models of speech (Schuster, 1999) or \n",
    "    - movements of physical objects (Graves, 2013). \n",
    "    - The mixture density strategy gives a way for the network \n",
    "        - to represent multiple output modes and \n",
    "        - to control the variance of its output, \n",
    "            - which is crucial for obtaining a high degree of quality in these real-valued domains. \n",
    "* An example of a mixture density network is shown in Fig.6.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.53.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we may wish to continue to model larger vectors $y$ containing more variables, and to impose <font color=\"red\">richer and richer structures on these output variables</font>.\n",
    "* For example, we may wish for our neural network to output a sequence of characters that forms a sentence.\n",
    "    - In these cases, we may continue \n",
    "        - to use the principle of maximum likelihood applied to our model $p(y;ω(x))$, \n",
    "        - but the model we use to describeybecomes complex enough to be beyond the scope of this chapter.\n",
    "* <font color=\"blue\">Chapter 10</font> describes how to use recurrent neural networks to deﬁne such <font color=\"blue\">models over sequences</font>, and \n",
    "* <font color=\"red\">Part III</font> describes advanced techniques for <font color=\"red\">modeling arbitrary probability distributions</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 Hidden Units\n",
    "* 6.3.1 Rectiﬁed Linear Units and Their Generalizations\n",
    "* 6.3.2 Logistic Sigmoid and Hyperbolic Tangent\n",
    "* 6.3.3 Other Hidden Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [10] CS231n: Convolutional Neural Networks for Visual Recognition : Training Neural Networks Part 1, activation functions, weight initialization, gradient flow, batch normalization, babysitting the learning process, hyperparameter optimization -   http://cs231n.stanford.edu/slides/winter1516_lecture5.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">how to choose the type of hidden unit to use in the hidden layers of the model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">The design of hidden units is an extremely active area of research and does not yet have many deﬁnitive guiding theoretical principles.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">Rectiﬁed linear units are an excellent default choice of hidden unit.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### diﬀerentiable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Some of the hidden units included in this list are not actually diﬀerentiable at all input points</font>. \n",
    "* For example, the rectiﬁed linear function g(z)=max{0, z}is not diﬀerentiable at z= 0. \n",
    "* This may seem like it invalidates g for use with a gradient-based learning algorithm. \n",
    "* <font color=\"red\">In practice, gradient descent still performs well enough for these models to be used for machine learning tasks</font>.\n",
    "* This is in part because neural network training algorithms do not usually arrive at a local minimum of the cost function, but <font color=\"red\">instead merely reduce its value signiﬁcantly</font>, as shown in Fig. 4.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/fig4.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://nn.readthedocs.org/en/rtd/image/relu.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  left derivative & right derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hidden units that are not diﬀerentiable are usually non-diﬀerentiable at only a small number of points.\n",
    "*  In general, a function g(z) has  \n",
    "    - a left derivative \n",
    "        - deﬁned by the slope of the function immediately to the left of z and \n",
    "    - a right derivative \n",
    "        - deﬁned by the slope of the function immediately to the right of z\n",
    "    - A function is diﬀerentiable at z only if both the left derivative and the right derivative are deﬁned and equal to each other.\n",
    "    - In the case of g(z) = max{0, z}, the left derivative at z= 0 is 0 and the right derivativeis 1.\n",
    "* The important point is that in practice one can safely disregard the non-diﬀerentiability of the hidden unit activation functions described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless indicated otherwise, <font color=\"red\">most hidden units</font> can be described as accepting a vector of inputs x, <font color=\"red\">computing an aﬃne transformation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.54.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then applying an <font color=\"red\">element-wise nonlinear function</font> g(z)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.1 Rectiﬁed Linear Units and Their Generalizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://nn.readthedocs.org/en/rtd/image/relu.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.55.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rectiﬁed linear units are easy to optimize because they are so similar to linear units.\n",
    "* first order derivate\n",
    "    - The only diﬀerence between a linear unit and a rectiﬁed linear unit is that a rectiﬁed linear unit outputs zero across half its domain. \n",
    "    - This makes the derivatives through a rectiﬁed linear unit remain large whenever the unit is active.\n",
    "    - The gradients are not only large but also consistent.\n",
    "* second order derivate\n",
    "    - <font color=\"red\">The second derivative of the rectifying operation is 0 almost everywhere, and the derivative of the rectifying operation is 1 everywhere that the unit is active</font>. \n",
    "    - This means that the gradient direction is far more useful for learning than it would be with activation functions that introduce second-order eﬀects.\n",
    "    <img src=\"http://img.sparknotes.com/figures/6/6feb2790f92651105afa8c668bf0b7ba/figure3-6-7.gif\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rectiﬁed linear units are typically used on top of an aﬃne transformation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.56.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">When initializing the parameters</font> of the aﬃne transformation, it can be a good practice to <font color=\"red\">set all elements of b to a small, positive value, such as 0.1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generalizations of rectiﬁed linear units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One drawback to rectiﬁed linear units is that they cannot learn via gradient-based methods on examples for which their activation is zero. \n",
    "* A variety of generalizations of rectiﬁed linear units guarantee that they receive gradient everywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three generalizations of rectified linear units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Absolute value rectiﬁcation\n",
    "    <img src=\"http://i.stack.imgur.com/P3xT5.png\" width=300 />\n",
    "* leaky ReLU & parametric ReLU (PReLU)\n",
    "    <img src=\"http://gforge.se/wp-content/uploads/2015/05/PReLU.jpg\" width=400 />\n",
    "* Maxout units\n",
    "    <img src=\"http://fastml.com/images/pylearn2/digits/maxout.png\"  width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Absolute valu rectification, leaky ReLU, parametric ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 참고\n",
    "* [11] Benchmarking ReLU and PReLU using MNIST and Theano - http://gforge.se/2015/06/benchmarking-relu-and-prelu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.57.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### maxout units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 참고\n",
    "* [12] Maxing out the digits - http://fastml.com/maxing-out-the-digits/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maxout units (Goodfellow et al., 2013a) generalize rectiﬁed linear units further. Instead of applying an element-wise functionn g(z), maxout units divide z into groups of k values. Each maxout unit then outputs the maximum element of one of these groups:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.58.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### maxout : learning the activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A maxout unit can learn a piecewise linear, convex function with up tokpieces.\n",
    "* <font color=\"red\">Maxout units can thus be seen as learning the activation function</font> itself rather than just the relationship between units. \n",
    "* <font color=\"red\">With large enough k, a maxout unit can learn to approximate any convex function with arbitrary ﬁdelity</font>.\n",
    "    -  In particular, a maxout layer with two pieces can learn to implement the same function of the input x as a traditional layer using \n",
    "        - the rectiﬁed linear activation function,\n",
    "        - absolutevalue rectiﬁcation function, or \n",
    "        - the leaky or parametric ReLU, or \n",
    "        - can learn to implement a totally diﬀerent function altogether."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### maxout : regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each maxout unit is now parametrized by k weight vectors instead of just one, so maxout units typically need more regularization than rectiﬁed linear units. \n",
    "* They can work well without regularization if the training set is large and the number of pieces per unit is kept low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### maxout : other benefits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Maxout units have a few other beneﬁts. \n",
    "* In some cases, one can gain some statistical and computational advantages by <font color=\"red\">requiring fewer parameters</font>.\n",
    "     - Speciﬁcally, if the features captured by n diﬀerent linear ﬁlters can be summarized without losing information by taking the max over each group of k features, then the next layer can get by with k times fewer weights.\n",
    "* Because each unit is driven by multiple ﬁlters, maxout units have some redundancy that helps them to <font color=\"red\">resist a phenomenon called catastrophic forgetting</font> in which neural networks forget how to perform tasks that they were trained on in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"> Rectiﬁed linear units and all of these generalizations of them are based on the principle that models are easier to optimize if their behavior is closer to linear</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.2 Logistic Sigmoid and Hyperbolic Tangent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.byclb.com/TR/Tutorials/neural_networks/ch7_1_dosyalar/image028.jpg\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to the introduction of rectiﬁed linear units, most neural networks used the <font color=\"red\">logistic sigmoid activation function</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.59.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the <font color=\"red\">hyperbolic tangent activation function</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.60.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These activation functions are closely related because"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.61.png\" width=200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have already seen sigmoid units as output units, used to predict the probability that a binary variable is 1\n",
    "* Unlike piecewise linear units, sigmoidal units saturate across most of their domain.\n",
    "* The widespread saturation of sigmoidal units can make gradient-based learning very diﬃcult.\n",
    "* <font color=\"red\">For this reason,their use as hidden units in feedforward networks is now discouraged.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hyperbolic tangent activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When a sigmoidal activation function must be used, the hyperbolic tangent activation function typically performs better than the logistic sigmoid.\n",
    "* This makes training the tanh network easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoidal activation functions are more common in settings other than feed-forward networks. \n",
    "* <font color=\"red\">Recurrent networks, many probabilistic models, and some autoencoders have additional requirements that rule out the use of piecewiselinear activation functions and make sigmoidal units more appealing despite th edrawbacks of saturation.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.62.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.3 Other Hidden Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many other types of hidden units are possible, but are used less frequently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, <font color=\"red\">a wide variety of diﬀerentiable functions perform perfectly well</font>.\n",
    "* Many unpublished activation functions perform just as well as the popular ones.\n",
    "* To provide a concrete example, the authors tested a feedforward network using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.63.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on the MNIST dataset and obtained an error rate of less than 1%, which is competitive with results obtained using more conventional activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During research and development of new techniques, it is common to test many diﬀerent activation functions and ﬁnd that several variations on standard practice perform comparably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be impractical to list all of the hidden unit types that have appearedin the literature. <font color=\"red\">We highlight a few especially useful and distinctive ones</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.64.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.65.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.66.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.67.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.68.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4 Architecture Design\n",
    "* 6.4.1 Universal Approximation Properties and Depth\n",
    "* 6.4.2 Other Architectural Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another key design consideration for neural networks is determining the architecture.\n",
    "* The word architecture refers to the overall structure of the network: <font color=\"red\">how many units it should have and how these units should be connected to each other</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layers & chain-based architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Most neural networks are organized into groups of units called layers. \n",
    "* Most neural network architectures arrange these layers in a chain structure, with each layer being a function of the layer that preceded it. \n",
    "* In this structure, the ﬁrst layeris given by\n",
    "    <img src=\"figures/cap6.69.png\" width=600 />\n",
    "* the second layer is given by\n",
    "    <img src=\"figures/cap6.70.png\" width=600 />\n",
    "* and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wider vs deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/deeper.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In these chain-based architectures, the main architectural considerations are to choose the depth of the network and the width of each layer. \n",
    "* As we will see, a network with even one hidden layer is suﬃcient to ﬁt the training set. \n",
    "* <font color=\"red\">Deeper networks often are able to use far fewer units per layer and far fewer parametersand often generalize to the test set, but are also often harder to optimize</font>. \n",
    "* The ideal network architecture for a task must be found via experimentation guided by monitoring the validation set error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.1 Universal Approximation Properties and Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In summary, a feedforward network with a single layer is suﬃcient to represent any function, but the layer may be infeasibly large and may fail to learn and generalize correctly. \n",
    "* In many circumstances, <font color=\"red\">using deeper models can reduce the number of units required to represent the desired function and can reduce the amount of generalization error</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.74.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.75.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.76.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.2 Other Architectural Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.77.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.78.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5 Back-Propagation and Other Diﬀerentiation Algorithms\n",
    "* 6.5.1 Computational Graphs\n",
    "* 6.5.2 Chain Rule of Calculus\n",
    "* 6.5.3 Recursively Applying the Chain Rule to Obtain Backprop\n",
    "* 6.5.4 Back-Propagation Computation in Fully-Connected MLP\n",
    "* 6.5.5 Symbol-to-Symbol Derivatives\n",
    "* 6.5.6 General Back-Propagation\n",
    "* 6.5.7 Example: Back-Propagation for MLP Training\n",
    "* 6.5.8 Complications\n",
    "* 6.5.9 Diﬀerentiation outside the Deep Learning Community\n",
    "* 6.5.10 Higher-Order Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고자료\n",
    "* [6] CS231n: Convolutional Neural Networks for Visual Recognition : Backpropagation & Introduction to neural networks - http://cs231n.stanford.edu/slides/winter1516_lecture4.pdf\n",
    "* [13] Neural Network 1: XOR 문제와 학습방법, Backpropagation (1986 breakthrough)- https://hunkim.github.io/ml/lec9.pdf\n",
    "* [15] 딥넷트웍 학습 시키기 (backpropagation) 비디오 - https://youtu.be/573EZkzfnZ0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### forward propagation & back-propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When we use a feedforward neural network to accept an input x and produce an output ˆy, information ﬂows forward through the network. \n",
    "* The inputs x providethe initial information that then propagates up to the hidden units at each layerand ﬁnally produces ˆy. This is called <font color=\"red\">forward propagation</font>.\n",
    "* During training,forward propagation can continue onward until it produces a scalar cost J(θ). \n",
    "* The <font color=\"red\">back-propagation</font> algorithm (Rumelhart et al., 1986a), often simply called backprop, allows the information from the cost to then ﬂow backwards through the network, in order to compute the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The term back-propagation is often misunderstood\n",
    "* The term back-propagation is often misunderstood as meaning the whole learning algorithm for multi-layer neural networks. \n",
    "* Actually, \n",
    "    - back-propagation refers only to the method for computing the gradient, \n",
    "    - while another algorithm, such as stochastic gradient descent, is used to perform learning using this gradient.\n",
    "* Furthermore, back-propagation is often misunderstood as being speciﬁc to multi-layer neural networks, \n",
    "    - but in principle it can compute derivatives of any function(for some functions, the correct response is to report that the derivative of the function is undeﬁned)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speciﬁcally, we will describe how to compute the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.79.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for an arbitrary function f, where x is a set of variables whose derivatives are desired, and y is an additional set of variables that are inputs to the function but whose derivatives are not required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In learning algorithms, the gradient we most often require is the gradient of the cost function with respect to the parameters,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.80.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Many machine learning tasks involve computing other derivatives, either as part of the learning process, or to analyze the learned model. \n",
    "* The back-propagation algorithm can be applied to these tasks as well, and is not restricted to computing the gradient of the cost function with respect to the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1 Computational Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### computational graph language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So far we have discussed neural networks with a relatively informal graph language.\n",
    "* To describe the back-propagation algorithm more precisely, it is helpful to have a more precise computational graph language.\n",
    "    - Many ways of formalizing computation as graphs are possible.\n",
    "    - Here, we use each node in the graph to indicate a variable. \n",
    "        - The variable maybe a \n",
    "            - scalar, \n",
    "            - vector, \n",
    "            - matrix, \n",
    "            - tensor, \n",
    "            - or even a variable of another type.\n",
    "     - operation\n",
    "         - To formalize our graphs, we also need to introduce the idea of an operation.\n",
    "         - An operation is a simple function of one or more variables. \n",
    "         - Our graph languageis accompanied by a set of allowable operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.81.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.82.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2 Chain Rule of Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고자료\n",
    "* [14] 특별편: 10분안에 미분 정리하기 비디오 - https://youtu.be/oZyvmtqLmLo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.92.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.83.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.84.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.85.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고 code\n",
    "* [16] backprop notes - http://cs231n.github.io/optimization-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/chain.png\" width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set some inputs\n",
    "x = -2; y = 5; z = -4\n",
    "\n",
    "# perform the forward pass\n",
    "q = x + y # q becomes 3\n",
    "f = q * z # f becomes -12\n",
    "\n",
    "# perform the backward pass (backpropagation) in reverse order:\n",
    "# first backprop through f = q * z\n",
    "dfdz = q # df/dz = q, so gradient on z becomes 3\n",
    "dfdq = z # df/dq = z, so gradient on q becomes -4\n",
    "# now backprop through q = x + y\n",
    "dfdx = 1.0 * dfdq # dq/dx = 1. And the multiplication here is the chain rule!\n",
    "dfdy = 1.0 * dfdq # dq/dy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2 5 -4\n",
      "3 -12\n",
      "3 -4\n",
      "-4.0 -4.0\n"
     ]
    }
   ],
   "source": [
    "print x, y, z\n",
    "print q, f\n",
    "print dfdz, dfdq\n",
    "print dfdx, dfdy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3 Recursively Applying the Chain Rule to Obtain Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.86.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.87.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.88.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.89.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.90.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.4 Back-Propagation Computation in Fully-Connected MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clarify the above deﬁnition of the back-propagation computation, let us considerthe speciﬁc graph associated with a fully-connected multi-layer MLP.\n",
    "* Algorithm 6.3 \n",
    "    - ﬁrst shows the forward propagation, which maps parameters to the supervised lossL(ˆy, y) associated with a single (input,target) training example(x, y), withˆy the output of the neural network when x is provided in input.\n",
    "* Algorithm 6.4 \n",
    "    - then shows the corresponding computation to be done for applying the back-propagation algorithm to this graph.\n",
    "* Algorithm 6.3 and Algorithm 6.4 are demonstrations that are chosen to be simple and straightforward to understand. However, they are specialized to one speciﬁc problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.91.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.94.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.95.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.5 Symbol-to-Symbol Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Algebraic expressions and computational graphs both operate on symbols, or variables that do not have speciﬁc values. \n",
    "* These algebraic and graph-based representations are called symbolic representations.\n",
    "* When we actually use ortrain a neural network, we must assign speciﬁc values to these symbols. Wereplace a symbolic input to the network x with a speciﬁc numeric value, such as $[1.2, 3.765, −1.8]^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.93.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.96.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.6 General Back-Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.97.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.98.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.99.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.100.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.101.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.7 Example: Back-Propagation for MLP Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.102.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.103.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.8 Complications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.9 Diﬀerentiation outside the Deep Learning Community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.104.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.105.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.10 Higher-Order Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.106.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.6 Historical Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료\n",
    "* [1] DEEP LEARNING (Yoshua Bengio)- http://www.deeplearningbook.org/\n",
    "* [2] L1 : From Machine Learning to Deep Learning (Udacity) -  https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63\n",
    "* [3] L1 : Deep Neural Networks (Udacity) https://drive.google.com/file/d/0B3vuuoFuJsKWdFFkMS10N1BpLTg/view\n",
    "* [4] CS231n: Convolutional Neural Networks for Visual Recognition : Image classification and the data-driven approach & k-nearest neighbor & Linear classification I - http://cs231n.stanford.edu/slides/winter1516_lecture2.pdf\n",
    "* [5] CS231n: Convolutional Neural Networks for Visual Recognition : Linear classification II & Higher-level representations, image features & Optimization, stochastic gradient descent - http://cs231n.stanford.edu/slides/winter1516_lecture3.pdf\n",
    "* [6] CS231n: Convolutional Neural Networks for Visual Recognition : Backpropagation & Introduction to neural networks - http://cs231n.stanford.edu/slides/winter1516_lecture4.pdf\n",
    "* [7] Convex analysis - https://msampler.wordpress.com/2009/07/08/convex-analysis/\n",
    "* [8] Affie Transformation - https://en.wikipedia.org/wiki/Affine_transformation\n",
    "* [9] Mixture Density Networks with TensorFlow - http://blog.otoro.net/2015/11/24/mixture-density-networks-with-tensorflow/\n",
    "* [10] CS231n: Convolutional Neural Networks for Visual Recognition : Training Neural Networks Part 1, activation functions, weight initialization, gradient flow, batch normalization, babysitting the learning process, hyperparameter optimization -   http://cs231n.stanford.edu/slides/winter1516_lecture5.pdf\n",
    "* [11] Benchmarking ReLU and PReLU using MNIST and Theano - http://gforge.se/2015/06/benchmarking-relu-and-prelu/\n",
    "* [12] Maxing out the digits - http://fastml.com/maxing-out-the-digits/\n",
    "* [13] Neural Network 1: XOR 문제와 학습방법, Backpropagation (1986 breakthrough)- https://hunkim.github.io/ml/lec9.pdf\n",
    "* [14] 특별편: 10분안에 미분 정리하기 비디오 - https://youtu.be/oZyvmtqLmLo\n",
    "* [15] 딥넷트웍 학습 시키기 (backpropagation) 비디오 - https://youtu.be/573EZkzfnZ0\n",
    "* [16] backprop notes - http://cs231n.github.io/optimization-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
