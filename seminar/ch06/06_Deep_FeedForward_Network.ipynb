{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 Deep Feedfowrd Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 딥러닝 세미나 : 이론 [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* 6.1 Example: Learning XOR\n",
    "* 6.2 Gradient-Based Learning\n",
    "    - 6.2.1 Cost Functions\n",
    "        - 6.2.1.1 Learning Conditional Distributions with Maximum Likelihood\n",
    "        - 6.2.1.2 Learning Conditional Statistics \n",
    "    - 6.2.2 Output Units\n",
    "        - 6.2.2.1 Linear Units for Gaussian Output Distributions\n",
    "        - 6.2.2.2 Sigmoid Units for Bernoulli Output Distributions\n",
    "        - 6.2.2.3 Softmax Units for Multinoulli Output Distributions\n",
    "        - 6.2.2.4 Other Output Types\n",
    "* 6.3 Hidden Units\n",
    "    - 6.3.1 Rectiﬁed Linear Units and Their Generalizations\n",
    "    - 6.3.2 Logistic Sigmoid and Hyperbolic Tangent\n",
    "    - 6.3.3 Other Hidden Units\n",
    "* 6.4 Architecture Design\n",
    "    - 6.4.1 Universal Approximation Properties and Depth\n",
    "    - 6.4.2 Other Architectural Considerations\n",
    "* 6.5 Back-Propagation and Other Diﬀerentiation Algorithms\n",
    "    - 6.5.1 Computational Graphs\n",
    "    - 6.5.2 Chain Rule of Calculus\n",
    "    - 6.5.3 Recursively Applying the Chain Rule to Obtain Backprop\n",
    "    - 6.5.4 Back-Propagation Computation in Fully-Connected MLP\n",
    "    - 6.5.5 Symbol-to-Symbol Derivatives\n",
    "    - 6.5.6 General Back-Propagation\n",
    "    - 6.5.7 Example: Back-Propagation for MLP Training\n",
    "    - 6.5.8 Complications\n",
    "    - 6.5.9 Diﬀerentiation outside the Deep Learning Community\n",
    "    - 6.5.10 Higher-Order Derivatives\n",
    "* 6.6 Historical Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [2] L1 : From Machine Learning to Deep Learning (Udacity) -  https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63\n",
    "* [3] L1 : Deep Neural Networks (Udacity) https://drive.google.com/file/d/0B3vuuoFuJsKWdFFkMS10N1BpLTg/view\n",
    "* [4] CS231n: Convolutional Neural Networks for Visual Recognition : Image classification and the data-driven approach & k-nearest neighbor & Linear classification I - http://cs231n.stanford.edu/slides/winter1516_lecture2.pdf\n",
    "* [5] CS231n: Convolutional Neural Networks for Visual Recognition : Linear classification II & Higher-level representations, image features & Optimization, stochastic gradient descent - http://cs231n.stanford.edu/slides/winter1516_lecture3.pdf\n",
    "* [6] CS231n: Convolutional Neural Networks for Visual Recognition : Backpropagation & Introduction to neural networks - http://cs231n.stanford.edu/slides/winter1516_lecture4.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models are called feedforward because information ﬂows through thefunction being evaluated from x, through the intermediate computations used to deﬁne f, and ﬁnally to the output y. \n",
    "* There are no feedback connections in whichoutputs of the model are feedback into itself. \n",
    "* When feedforward neural networksare extended to include feedback connections, they are called recurrent neuralnetworks, presented in Chapter 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedforward neural networks are called networks because they are typically represented by composing together many diﬀerent functions.\n",
    "* The model is associatedwith a directed acyclic graph describing how the functions are composed together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, \n",
    "* we might have three functions $f^{(1)}$, $f^{(2)}$, and $f^{(3)}$ connected in a chain, to form f(x) = $f^{(3)}(f^{(2)}(f^{(1)}(x)))$.\n",
    "* $f^{(1)}$ is called the ﬁrst layer of the network, $f^{(2)}$ is called the second layer, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall length of the chain gives the depth of the model. \n",
    "* It is from this terminology that the name “deep learning” arises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ﬁnal layer of a feedforward network is called the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During neural network training, we drive f(x) to match $f^∗(x)$. \n",
    "* The training data provides us with noisy, approximate examples of $f^∗(x)$ evaluated at diﬀerent training points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each examplexis accompanied by a label $y ≈ f^∗(x)$.\n",
    "* The training examples specify directly what the output layer must do at each point x; \n",
    "* it must produce a value that is close to y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning algorithm must decidehow to use those layers to produce the desired output, but the training data does not say what each individual layer should do. * Instead, the learning algorithm mustdecide how to use these layers to best implement an approximation of $f^∗$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because the training data does not show the desired output for each of these layers, these layers are called hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, these networks are called neural because they are loosely inspired by neuroscience. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The goal of modern neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, modern neural network research is guided by many mathematical and engineering disciplines, and the goal of neural networks is not to perfectly model the brain. \n",
    "* It is best to think of feedforward networks as function approximation machines that are designed to achieve statistical generalization, occasionally drawing some insights from what we know about the brain, rather than as models of brain function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to understand feedforward networks is to begin with linear models and consider how to overcome their limitations. \n",
    "* Linear models, such as logistic regression and linear regression, are appealing because they may be ﬁt eﬃciently and reliably, either in closed form or with convex optimization. \n",
    "* Linear models also have the obvious defect that the model capacity is limited to linear functions, so the model cannot understand the interaction between any two input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nonlinear transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extend linear models to represent nonlinear functions of x, we can apply the linear model not to x itself but to a transformed input φ(x), where φis a nonlinear transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The question is then how to choose the mapping φ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.One option is to use a very generic φ, such as the inﬁnite-dimensional φ that is implicitly used by kernel machines based on the RBF kernel. \n",
    "* If φ(x) is of high enough dimension, we can always have enough capacity to ﬁt thetraining set, but generalization to the test set often remains poor. \n",
    "* Very generic feature mappings are usually based only on the principle of local smoothness and do not encode enough prior information to solve advanced problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Another option is to manually engineer φ.\n",
    "* Until the advent of deep learning, this was the dominant approach. \n",
    "* This approach requires decades of human eﬀort for each separate task, with practitioners specializing in diﬀerent domains such as speech recognition or computer vision, and with little transfer between domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.The strategy of deep learning is to learn φ. \n",
    "* In this approach, we have a model y = f(x;θ,w) = $φ(x;θ)^{\\top}w$. \n",
    "* We now have parameters θ that we use to learn φ from a broad class of functions, and parameters w that map from φ(x) to the desired output. \n",
    "* This is an example of a deep feedforward network, with φ deﬁning a hidden layer. \n",
    "* This approach is the only one of the three that gives up on the convexity of the training problem, but the beneﬁts outweigh the harms. \n",
    "* In this approach, we parametrize the representation as φ(x;θ) and use the optimization algorithm to ﬁnd the θ that corresponds to a good representation. \n",
    "* If we wish, this approach can capture the beneﬁt of the ﬁrst approach by being highly generic—we do so by using a very broad family φ(x;θ). \n",
    "* This approach can also capture the beneﬁt of the second approach.\n",
    "* Human practitioners can encode their knowledge to help generalization by designing families φ(x;θ) that they expect will perform well. \n",
    "* The advantage is that the human designer only needs to ﬁnd the right general function family rather than ﬁnding precisely the right function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Example: Learning XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XOR function (“exclusive or”) is an operation on two binary values,x1 and x2. When exactly one of these binary values is equal to 1, the XOR function returns 1. Otherwise, it returns 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can treat this problem as a regression problem and use a mean squared error loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Linear_least_squares_example2.svg/500px-Linear_least_squares_example2.svg.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example, we will not be concerned with statistical generalization.We want our network to perform correctly on the four points X={ $[0,0]^{\\top}$,  $[0,1]^{\\top}$, $[1,0]^{\\top}$, and $[1,1]^{\\top}$}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After solving the normal equations, we obtain w=0 and b=1/2. The linear model simply outputs 0.5 everywhere. Why does this happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speciﬁcally, we will introduce a very simple feedforward network with onehidden layer containing two hidden units. See Fig. 6.2 for an illustration of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f^{(1)}(x;W,c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h=^{f(1)}(x;W,c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y=f^{(2)}(h;w,b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(x;W,c,w,b) = $f^{(2)}(f^{(1)}(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f^{(1)}(x)=W^{\\top}x$ and $f^{(2)}(h)=h^{\\top}w$. Then $f(x)=w^{\\top}W^{\\top}x$. We could represent this function as f(x) = $x^{\\top}w^{\\prime}$ where $w^{\\prime}= Ww$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h=g(W^{\\top}x+c)$,where W provides the weights of a linear transformation and c the biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation functiong is typically chosen to be a function that is applied element-wise, with $h_{i}=g(x^{\\top}W:,_{i}+c_{i})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rectiﬁed linear unit or ReLU\n",
    "g(z) = max{0, z}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this example, we simply speciﬁed the solution, then showed that it obtained zero error. \n",
    "* In a real situation, there might be billions of model parameters and billions of training examples, so one cannot simply guess the solution as we did here. \n",
    "* <font color=\"red\">Instead, a gradient-based optimization algorithm can ﬁnd parameters thatproduce very little error.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Gradient-Based Learning\n",
    "* 6.2.1 Cost Functions\n",
    "* 6.2.2 Output Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Designing and training a neural network is not much diﬀerent from training any other machine learning model with gradient descent.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://qph.is.quoracdn.net/main-qimg-46a77c77c721ba34283308232a1788c8?convert_to_webp=true\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">The largest diﬀerence between the linear models we have seen so far and neural networks is that the nonlinearity of a neural network causes most interesting loss functions to become non-convex.  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [7] Convex analysis - https://msampler.wordpress.com/2009/07/08/convex-analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://msampler.files.wordpress.com/2009/07/cvx-fun.gif\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stocastic gradient decent VS others(linear equation solver, convex optimization) \n",
    "* This means that neural networks are usually trained by using iterative, gradient-based optimizers that merely <font color=\"red\">drive the cost function to a very low value</font>, rather than the linear equation solvers used to train linear regression models or the convex optimization algorithms with global convergence guarantees used to train logistic regression or SVMs.\n",
    "* Convex optimization converges starting from any initial parameters (in theory—in practice it is very robust but can encounter numerical problems). \n",
    "* Stochastic gradient descent appliedto non-convex loss functions has <font color=\"red\">no such convergence guarantee</font>, and is <font color=\"red\">sensitive to the values of the initial parameters</font>.\n",
    "* <font color=\"blue\">For feedforward neural networks, it is important to initialize all weights to small random values. The biases may be initialized to zero or to small positive values.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://camo.githubusercontent.com/30bf2d42d3a9b0e07dbc03a014f4e36dbc06904f/68747470733a2f2f7261772e6769746875622e636f6d2f7175696e6e6c69752f4d616368696e654c6561726e696e672f6d61737465722f696d61676573466f724578706c616e6174696f6e2f4772616469656e7444657363656e74576974684d75746c69706c654c6f63616c4d696e696d756d2e6a7067\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.holehouse.org/mlclass/17_Large_Scale_Machine_Learning_files/Image%20[16].png\"   />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://43284bdcf41602d9ee3b7f9155623bc4db1a5d55.googledrive.com/host/0B56ak7W-HmqASVBYZTJ1WXVoQUU/img/stochastic.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.slidesharecdn.com/nn-150216124050-conversion-gate01/95/neural-networks-overview-11-638.jpg?cb=1424102465\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can of course, train models such as linear regression and support vector machines with gradient descent too, and in fact this is <font color=\"red\">common when the trainingset is extremely large.</font>\n",
    "* From this point of view, training a neural network is notmuch diﬀerent from training any other model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with other machine learning models, <font color=\"red\">to apply gradient-based learning</font> we must choose a <font color=\"blue\">cost function</font>, and we must choose how to <font color=\"blue\">represent the output of the model</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total cost function used to train a neural network will often combine one of the primary cost functions described here with a <font color=\"red\">regularization term</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.1 Cost Functions\n",
    "* 6.2.1.1 Learning Conditional Distributions with Maximum Likelihood\n",
    "* 6.2.1.2 Learning Conditional Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important aspect of the design of a deep neural network is the <font color=\"red\">choice of the cost function</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### priciple of of maximum likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(y | x;θ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In most cases, our <font color=\"red\">parametric model</font> deﬁnes a distributionp(y|x;θ) and we simply use the <font color=\"blue\">principle of maximum likelihood</font>. \n",
    "* This means we use the <font color=\"red\">cross-entropy</font> <font color=\"blue\">between the training data and the model’s predictions</font> as the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://statgen.iop.kcl.ac.uk/media/ml1.gif\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Mplwp_shannon_entropy.svg/2000px-Mplwp_shannon_entropy.svg.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://colah.github.io/posts/2015-09-Visual-Information/img/CrossEntropyDef.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/math/5/7/9/57915b0c4d0e62a602db5e757742b1d3.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cfile4.uf.tistory.com/image/2645033951991C20193341\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63/res/1ff6f90c-d594-468b-86a2-d70289958ce8.png?resizeSmall&width=832\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.slidesharecdn.com/215implementingdeeplearningusingcudnn-150915052020-lva1-app6892/95/251-implementing-deep-learning-using-cu-dnn-17-638.jpg?cb=1442295596\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/svmvssoftmax.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://images.slideplayer.com/11/3277991/slides/slide_57.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://qph.is.quoracdn.net/main-qimg-9e2d012ef7cb8b29d2bed14d2975c986?convert_to_webp=true\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://qiita-image-store.s3.amazonaws.com/0/100523/195fb6d9-adf6-9166-5c81-08665777032d.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://2.bp.blogspot.com/-EVROdmAZ0No/VoTHrtrREZI/AAAAAAAAAn0/gyKG0BUjst8/s1600/softmax-regression-scalargraph.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63/res/d6f7961c-b05d-495d-af14-4d6a21feecdf.png?resizeSmall&width=832\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1.1 Learning Conditional Distributions with Maximum Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://statgen.iop.kcl.ac.uk/media/ml2.gif\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63/res/d6f7961c-b05d-495d-af14-4d6a21feecdf.png?resizeSmall&width=832\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most modern neural networks are trained using maximum likelihood. This means that the cost function is simply the <font color=\"red\">negative log-likelihood</font>, <font color=\"blue\">equivalently described as the cross-entropy between the training data and the model distribution</font>. This cost function is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speciﬁc form of the cost function changes from model to model, dependingon the speciﬁc form of $log p_{model}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if $p_{model}(y|x) = N(y;f(x;θ),I)$,then we recover the mean squared error cost,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "up to a scaling factor of $\\frac{1}{2}$ and a term that does not depend on θ. The discarded constant is based on the variance of the Gaussian distribution, which in this casewe chose not to parametrize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we saw that the equivalence between maximum likelihood estimation with an output distribution and minimization of mean squared error holds for a linear model, but in fact, the equivalence holds regardless of the f(x; θ) used to predict the mean of the Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">An advantage of this approach of deriving the cost function from maximum likelihood is that it removes the burden of designing cost functions for each model</font>.  Specifying a model $p(y|x)$ automatically determines a cost function $logp(y|x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">One recurring theme throughout neural network design is that the gradient ofthe cost function must be large and predictable enough to serve as a good guidefor the learning algorithm.</font>\n",
    "* Functions that saturate (become very ﬂat) undermine this objective because they make the gradient become very small. \n",
    "* In many cases this happens because the activation functions used to produce the output of thehidden units or the output units saturate.\n",
    "* <font color=\"red\">The negative log-likelihood helps to avoid this problem for many models</font>. \n",
    "    - Many output units involve an exp function that can saturate when its argument is very negative.\n",
    "    - The log function in the negative log-likelihood cost function undoes the exp of some output units. \n",
    "    - We will discuss the interaction between the cost function and the choice of output unit inSec. 6.2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">One unusual property of the cross-entropy cost used to perform maximum likelihood estimation</font> is that it usually does not have a minimum value when applied to the models commonly used in practice.\n",
    "* <font color=\"blue\">For discrete output variables</font>, most models are parametrized in such a way that they <font color=\"blue\">cannot represent a probability of zero or one, but can come arbitrarily close to doing so</font>. Logistic regressionis an example of such a model.\n",
    "* <font color=\"red\">For real-valued output variables</font>, if the model can control the <font color=\"red\">density of the output distribution</font> (for example, by learning the variance parameter of a Gaussian output distribution) then it <font color=\"red\">becomes possible to assign extremely high density</font> to the correct training set outputs, resulting <font color=\"red\">in cross-entropy approaching negative inﬁnity</font>.\n",
    "* <font color=\"blue\">Regularization techniques</font> described in Chapter 7 provide several diﬀerent ways of modifying the learning problem sothat the model cannot reap unlimited reward in this way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1.2 Learning Conditional Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.mwclearning.com/wp-content/uploads/2011/04/conditionalProb.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.cvlibs.net/projects/gausspro/gausspro02.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of learning a full probability distribution p(y|x;θ) we often want to learn just one conditional statistic of y given x.\n",
    "* For example, we may have a predictor f(x;θ) that we wish to predict the mean of y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">If we use a suﬃciently powerful neural network</font>, <font color=\"blue\">we can think of the neural network as being able to represent any function $f$ from a wide class of functions</font>, with this class being limited only by features such as continuity and boundedness rather than by having a speciﬁc parametric form.\n",
    "* From this point of view, <font color=\"blue\">we can view the cost function as being a functional</font> rather than just a function. \n",
    "    - A functional is a mapping from functions to real numbers.\n",
    "* <font color=\"red\">We can thus think of learning as choosing a function rather than merely choosing a set of parameters</font>.\n",
    "* <font color=\"blue\">We can design our cost functional to have its minimum occur at some speciﬁcfunction we desire.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculus of variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving an <font color=\"red\">optimization problem with respect to a function</font> requires a mathematical tool called calculus of variations, described in Sec. 19.4.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculus of variations may be used to derive the following two results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* so long as this function lies within the class we optimize over. \n",
    "* In other words, if we could train on inﬁnitely many samples from the true data-generating distribution, minimizing the mean squared error cost function gives a function that predicts the mean of y for each value of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, <font color=\"red\">mean squared error and mean absolute error often lead to poor results when used with gradient-based optimization</font>. \n",
    "* Some output units that saturate produce very small \n",
    "* <font color=\"blue\">This is one reason that the cross-entropy cost function is more popular</font> than mean squared error or mean absolute error, even when it is not necessary to estimate an entire distribution p(y|x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.2 Output Units\n",
    "* 6.2.2.1 Linear Units for Gaussian Output Distributions\n",
    "* 6.2.2.2 Sigmoid Units for Bernoulli Output Distributions\n",
    "* 6.2.2.3 Softmax Units for Multinoulli Output Distributions\n",
    "* 6.2.2.4 Other Output Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">The choice of cost function is tightly coupled with the choice of output unit</font>\n",
    "* Most of the time, we simply use the cross-entropy between the data distribution and the model distribution. \n",
    "* <font color=\"blue\">The choice of how to represent the output then determines the form of the cross-entropy function</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this section, we suppose that the feedforward network provides a set of hidden features deﬁned by h=f(x;θ). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The role of the output layer is then to provide some additional transformation from the features to complete the task that the network must perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2.1 Linear Units for Gaussian Output Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [8] Affie Transformation - https://en.wikipedia.org/wiki/Affine_transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.publiclab.org/system/images/photos/000/004/507/original/geometric-transformations.jpg\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/350px-Normal_Distribution_PDF.svg.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple kind of output unit is an output unit based on an <font color=\"red\">aﬃne transformation with no nonlinearity</font>. These are often just called linear units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.13.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximizing the log-likelihood is then equivalent to minimizing the mean squared error\n",
    "* The maximum likelihood framework \n",
    "    - makes it straight forward to learn the covariance of the Gaussian too, or \n",
    "    - to make the covariance of the Gaussian be a function of the input. \n",
    "    - However, the covariance must be constrained to be a positive deﬁnite matrix for all inputs. \n",
    "    - It is diﬃcult to satisfy such constraints with a linear output layer, so typically other output units are used to parametrize the covariance.\n",
    "    - Approaches to modeling the covariance are described shortly, in Sec. 6.2.2.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2.2 Sigmoid Units for Bernoulli Output Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.14.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.15.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.16.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.17.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2.3 Softmax Units for Multinoulli Output Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.18.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.19.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.20.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.21.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.22.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.23.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.24.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2.4 Other Output Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.25.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.26.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.27.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.28.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.29.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.30.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.31.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.32.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.33.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.34.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.35.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.36.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.37.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.38.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.39.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.40.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.41.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.42.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.43.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.44.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.45.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.46.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.47.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.48.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.49.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.50.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.51.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.52.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.53.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 Hidden Units\n",
    "* 6.3.1 Rectiﬁed Linear Units and Their Generalizations\n",
    "* 6.3.2 Logistic Sigmoid and Hyperbolic Tangent\n",
    "* 6.3.3 Other Hidden Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.54.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.55.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.1 Rectiﬁed Linear Units and Their Generalizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.56.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.57.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.58.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.2 Logistic Sigmoid and Hyperbolic Tangent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.59.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.60.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.61.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.62.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.3 Other Hidden Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.63.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.64.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.65.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.66.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.67.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.68.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4 Architecture Design\n",
    "* 6.4.1 Universal Approximation Properties and Depth\n",
    "* 6.4.2 Other Architectural Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.69.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.70.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.1 Universal Approximation Properties and Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.71.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.72.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.73.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.74.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.75.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.76.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.2 Other Architectural Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.77.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.78.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5 Back-Propagation and Other Diﬀerentiation Algorithms\n",
    "* 6.5.1 Computational Graphs\n",
    "* 6.5.2 Chain Rule of Calculus\n",
    "* 6.5.3 Recursively Applying the Chain Rule to Obtain Backprop\n",
    "* 6.5.4 Back-Propagation Computation in Fully-Connected MLP\n",
    "* 6.5.5 Symbol-to-Symbol Derivatives\n",
    "* 6.5.6 General Back-Propagation\n",
    "* 6.5.7 Example: Back-Propagation for MLP Training\n",
    "* 6.5.8 Complications\n",
    "* 6.5.9 Diﬀerentiation outside the Deep Learning Community\n",
    "* 6.5.10 Higher-Order Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.79.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.80.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.1 Computational Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.81.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.82.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.2 Chain Rule of Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.83.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.84.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.85.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.3 Recursively Applying the Chain Rule to Obtain Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.86.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.87.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.88.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.89.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.90.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.4 Back-Propagation Computation in Fully-Connected MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.91.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.5 Symbol-to-Symbol Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.92.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.93.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.94.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.95.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.96.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.6 General Back-Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.97.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.98.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.99.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.100.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.101.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.7 Example: Back-Propagation for MLP Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.102.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.103.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.8 Complications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.9 Diﬀerentiation outside the Deep Learning Community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.104.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.105.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5.10 Higher-Order Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.106.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.6 Historical Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료\n",
    "* [1] DEEP LEARNING (Yoshua Bengio)- http://www.deeplearningbook.org/\n",
    "* [2] L1 : From Machine Learning to Deep Learning (Udacity) -  https://www.evernote.com/shard/s142/sh/d8bfa5b8-9bb6-4651-947b-2d5623a75723/a14f4e5fb17aaa63\n",
    "* [3] L1 : Deep Neural Networks (Udacity) https://drive.google.com/file/d/0B3vuuoFuJsKWdFFkMS10N1BpLTg/view\n",
    "* [4] CS231n: Convolutional Neural Networks for Visual Recognition : Image classification and the data-driven approach & k-nearest neighbor & Linear classification I - http://cs231n.stanford.edu/slides/winter1516_lecture2.pdf\n",
    "* [5] CS231n: Convolutional Neural Networks for Visual Recognition : Linear classification II & Higher-level representations, image features & Optimization, stochastic gradient descent - http://cs231n.stanford.edu/slides/winter1516_lecture3.pdf\n",
    "* [6] CS231n: Convolutional Neural Networks for Visual Recognition : Backpropagation & Introduction to neural networks - http://cs231n.stanford.edu/slides/winter1516_lecture4.pdf\n",
    "* [7] Convex analysis - https://msampler.wordpress.com/2009/07/08/convex-analysis/\n",
    "* [8] Affie Transformation - https://en.wikipedia.org/wiki/Affine_transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
