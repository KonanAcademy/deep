{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8. Optimization for Training DeepModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 딥러닝 세미나 : 이론 [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* 8.1 How Learning Diﬀers from Pure Optimization\n",
    "    - 8.1.1 Empirical Risk Minimization\n",
    "    - 8.1.2 Surrogate Loss Functions and Early Stopping\n",
    "    - 8.1.3 Batch and Minibatch Algorithms\n",
    "* 8.2 Challenges in Neural Network Optimization\n",
    "    - 8.2.1 Ill-Conditioning\n",
    "    - 8.2.2 Local Minima\n",
    "    - 8.2.3 Plateaus, Saddle Points and Other Flat Regions\n",
    "    - 8.2.4 Cliﬀs and Exploding Gradients\n",
    "    - 8.2.5 Long-Term Dependencies\n",
    "    - 8.2.6 Inexact Gradients\n",
    "    - 8.2.7 Poor Correspondence between Local and Global Structure\n",
    "    - 8.2.8 Theoretical Limits of Optimization\n",
    "* 8.3 Basic Algorithms\n",
    "    - 8.3.1 Stochastic Gradient Descent\n",
    "    - 8.3.2 Momentum\n",
    "    - 8.3.3 Nesterov Momentum\n",
    "* 8.4 Parameter Initialization Strategies\n",
    "* 8.5 Algorithms with Adaptive Learning Rates\n",
    "    - 8.5.1 AdaGrad\n",
    "    - 8.5.2 RMSProp\n",
    "    - 8.5.3 Adam\n",
    "    - 8.5.4 Choosing the Right Optimization Algorithm\n",
    "* 8.6 Approximate Second-Order Methods\n",
    "    - 8.6.1 Newton’s Method\n",
    "    - 8.6.2 Conjugate Gradients\n",
    "    - 8.6.3 BFGS\n",
    "* 8.7 Optimization Strategies and Meta-Algorithms\n",
    "    - 8.7.1 Batch Normalization\n",
    "    - 8.7.2 Coordinate Descent\n",
    "    - 8.7.3 Polyak Averaging\n",
    "    - 8.7.4 Supervised Pretraining\n",
    "    - 8.7.5 Designing Models to Aid Optimization\n",
    "    - 8.7.6 Continuation Methods and Curriculum Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [2] An overview of gradient descent optimization algorithms - http://sebastianruder.com/optimizing-gradient-descent/index.html\n",
    "* [3] Stochastic gradient methods for machine learning - http://research.microsoft.com/en-us/um/cambridge/events/mls2013/downloads/stochastic_gradient.pdf\n",
    "* [4] (OXFORD, Machine Learning: 2014-2015 )Deep Learning Lecture 6: Optimization - https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/lecture5.pdf\n",
    "* [5] 다크프로그래머 : Gradient, Jacobian 행렬, Hessian 행렬, Laplacian- http://darkpgmr.tistory.com/132\n",
    "* [6] 조금은 느리게 살자 : 테일러 급수(級數, Taylor series) - http://ghebook.blogspot.kr/2010/07/taylor-series.html\n",
    "* [7] 다크프로그래머 : 테일러 급수의 이해와 활용 (Taylor series) - http://darkpgmr.tistory.com/59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter presents these optimization techniques for neural network training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://qph.is.quoracdn.net/main-qimg-46a77c77c721ba34283308232a1788c8?convert_to_webp=true\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://msampler.files.wordpress.com/2009/07/cvx-fun.gif\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://camo.githubusercontent.com/30bf2d42d3a9b0e07dbc03a014f4e36dbc06904f/68747470733a2f2f7261772e6769746875622e636f6d2f7175696e6e6c69752f4d616368696e654c6561726e696e672f6d61737465722f696d61676573466f724578706c616e6174696f6e2f4772616469656e7444657363656e74576974684d75746c69706c654c6f63616c4d696e696d756d2e6a7067\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.slidesharecdn.com/aihandson20140710bslideshare-140716182318-phpapp02/95/jsais-ai-tool-introduction-deep-learning-pylearn2-and-torch7-52-638.jpg?cb=1435207500\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">This chapter focuses on one particular case of optimization</font>: \n",
    "* ﬁnding the parameters $θ$ of a neural network that signiﬁcantly reduce a cost function $J(θ)$, which typically includes a performance measure evaluated on the entire training set as well as additional regularization terms.\n",
    "    <img src=\"http://cs231n.github.io/assets/dataflow.jpeg\" />\n",
    "* We begin with a description of how optimization used as a training algorithm for a machine learning task diﬀers from pure optimization. \n",
    "* Next, we present several of the concrete challenges that make optimization of neural networks diﬃcult. \n",
    "* We then deﬁne several practical algorithms, including both\n",
    "    - optimization algorithms themselves and \n",
    "    - strategies for initializing the parameters. \n",
    "* More advanced algorithms adapt \n",
    "    - their learning rates during training or \n",
    "    - leverage information contained in the second derivatives of the cost function\n",
    "* Finally, we conclude with a review of \n",
    "    - several optimization strategies that are formed by \n",
    "        - combining simple optimization algorithms \n",
    "            - into higher-level procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.1 How Learning Diﬀers from Pure Optimization\n",
    "* 8.1.1 Empirical Risk Minimization\n",
    "* 8.1.2 Surrogate Loss Functions and Early Stopping\n",
    "* 8.1.3 Batch and Minibatch Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization algorithms used for training of deep models diﬀer from traditional optimization algorithms in several ways.\n",
    "* Machine learning usually acts indirectly.\n",
    "    - In most machine learning scenarios, \n",
    "        - we care about some performance measure $P$, \n",
    "            - that is deﬁned with respect to the test set and \n",
    "            - may also be intractable. \n",
    "    - We therefore optimize $P$ only indirectly. \n",
    "* We reduce a diﬀerent cost function $J(θ)$ in the hope that \n",
    "    - doing so will improve P. \n",
    "* This is in contrast to pure optimization,where minimizing \n",
    "    - $J$ is a goal in and of itself. \n",
    "* Optimization algorithms for training deep models \n",
    "    - also typically include \n",
    "        - some specialization \n",
    "            - on the speciﬁc structure \n",
    "                - of machine learning objective functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, the cost function can be written as an average over the training set,such as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whereLis the per-example loss function, $f(x;θ)$ is the predicted output whenthe input is $x$, $ˆp$ data is the empirical distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data generating distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Eq. 8.1 deﬁnes an objective function with respect to the training s\n",
    "* We would usually prefer to minimize \n",
    "    - the corresponding objective function \n",
    "        - where the expectation is taken across \n",
    "            - the data generating distribution $p$ data \n",
    "                - rather than just over the ﬁnite training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.1 Empirical Risk Minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [8] Empirical Risk Minimization - http://demo.clab.cs.cmu.edu/fa2015-11763/slides/erm.pdf\n",
    "* [9] The Learning Problem and Regularization - http://www.mit.edu/~9.520/spring11/slides/class02.pdf\n",
    "* [10] Risk Minimization - http://hellbell.tistory.com/entry/Risk-Minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.svms.org/srm/Rychetsky2001_2-4.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to convert a machine learning problem back into an optimization problem is to minimize the expected loss on the training set. \n",
    "* This means replacing the true distribution $p(x, y)$ with the empirical distribution $ˆp(x, y)$ deﬁned by the training set. \n",
    "* We now minimize the empirical risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where m is the number of training examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process based on minimizing this average training error is known as <font color=\"red\">empirical risk minimization</font>.\n",
    "* In this setting, machine learning is still very similarto straightforward optimization. \n",
    "* Rather than optimizing the risk directly, \n",
    "    - we optimize the empirical risk, \n",
    "    - and hope that \n",
    "        - the risk decreases signiﬁcantly as well.\n",
    "* A variety of theoretical results establish conditions under which the true risk can be expected to decrease by various amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">However, empirical risk minimization is prone to overﬁtting</font>. \n",
    "* Models with high capacity can simply memorize the training set. In many cases, empirical risk minimization is not really feasible. \n",
    "    - The most eﬀective modern optimizationalgorithms are based on gradient descent, but many useful loss functions, suchas 0-1 loss, have no useful derivatives (the derivative is either zero or undeﬁnedeverywhere). \n",
    "* These two problems mean that, <font color=\"red\">in the context of deep learning, werarely use empirical risk minimization</font>. \n",
    "* Instead, we must use a slightly diﬀerent approach, in which the quantity that we actually optimize is even more diﬀerent from the quantity that we truly want to optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.2 Surrogate Loss Functions and Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.3 Batch and Minibatch Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2 Challenges in Neural Network Optimization\n",
    "* 8.2.1 Ill-Conditioning\n",
    "* 8.2.2 Local Minima\n",
    "* 8.2.3 Plateaus, Saddle Points and Other Flat Regions\n",
    "* 8.2.4 Cliﬀs and Exploding Gradients\n",
    "* 8.2.5 Long-Term Dependencies\n",
    "* 8.2.6 Inexact Gradients\n",
    "* 8.2.7 Poor Correspondence between Local and Global Structure\n",
    "* 8.2.8 Theoretical Limits of Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.1 Ill-Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.2 Local Minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.3 Plateaus, Saddle Points and Other Flat Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.12.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.4 Cliﬀs and Exploding Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.13.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.5 Long-Term Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.14.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.6 Inexact Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.7 Poor Correspondence between Local and Global Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.15.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.16.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2.8 Theoretical Limits of Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.3 Basic Algorithms\n",
    "* 8.3.1 Stochastic Gradient Descent\n",
    "* 8.3.2 Momentum\n",
    "* 8.3.3 Nesterov Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<img src=\"figures/cap8.17.png\" width=600 />\n",
    "<img src=\"figures/cap8.18.png\" width=600 />\n",
    "<img src=\"figures/cap8.19.png\" width=600 />\n",
    "<img src=\"figures/cap8.20.png\" width=600 />\n",
    "<img src=\"figures/cap8.21.png\" width=600 />\n",
    "<img src=\"figures/cap8.22.png\" width=600 />\n",
    "<img src=\"figures/cap8.23.png\" width=600 />\n",
    "<img src=\"figures/cap8.24.png\" width=600 />\n",
    "<img src=\"figures/cap8.25.png\" width=600 />\n",
    "<img src=\"figures/cap8.26.png\" width=600 />\n",
    "<img src=\"figures/cap8.27.png\" width=600 />\n",
    "<img src=\"figures/cap8.28.png\" width=600 />\n",
    "<img src=\"figures/cap8.29.png\" width=600 />\n",
    "<img src=\"figures/cap8.30.png\" width=600 />\n",
    "<img src=\"figures/cap8.31.png\" width=600 />\n",
    "<img src=\"figures/cap8.32.png\" width=600 />\n",
    "<img src=\"figures/cap8.33.png\" width=600 />\n",
    "<img src=\"figures/cap8.34.png\" width=600 />\n",
    "<img src=\"figures/cap8.35.png\" width=600 />\n",
    "<img src=\"figures/cap8.36.png\" width=600 />\n",
    "<img src=\"figures/cap8.37.png\" width=600 />\n",
    "<img src=\"figures/cap8.38.png\" width=600 />\n",
    "<img src=\"figures/cap8.39.png\" width=600 />\n",
    "<img src=\"figures/cap8.40.png\" width=600 />\n",
    "<img src=\"figures/cap8.41.png\" width=600 />\n",
    "<img src=\"figures/cap8.42.png\" width=600 />\n",
    "<img src=\"figures/cap8.43.png\" width=600 />\n",
    "<img src=\"figures/cap8.44.png\" width=600 />\n",
    "<img src=\"figures/cap8.45.png\" width=600 />\n",
    "<img src=\"figures/cap8.46.png\" width=600 />\n",
    "<img src=\"figures/cap8.47.png\" width=600 />\n",
    "<img src=\"figures/cap8.48.png\" width=600 />\n",
    "<img src=\"figures/cap8.49.png\" width=600 />\n",
    "<img src=\"figures/cap8.50.png\" width=600 />\n",
    "<img src=\"figures/cap8.51.png\" width=600 />\n",
    "<img src=\"figures/cap8.52.png\" width=600 />\n",
    "<img src=\"figures/cap8.53.png\" width=600 />\n",
    "<img src=\"figures/cap8.54.png\" width=600 />\n",
    "<img src=\"figures/cap8.55.png\" width=600 />\n",
    "<img src=\"figures/cap8.56.png\" width=600 />\n",
    "<img src=\"figures/cap8.57.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3.1 Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3.2 Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3.3 Nesterov Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.4 Parameter Initialization Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.5 Algorithms with Adaptive Learning Rates\n",
    "* 8.5.1 AdaGrad\n",
    "* 8.5.2 RMSProp\n",
    "* 8.5.3 Adam\n",
    "* 8.5.4 Choosing the Right Optimization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5.1 AdaGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5.2 RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5.3 Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5.4 Choosing the Right Optimization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.6 Approximate Second-Order Methods\n",
    "* 8.6.1 Newton’s Method\n",
    "* 8.6.2 Conjugate Gradients\n",
    "* 8.6.3 BFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6.1 Newton’s Method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6.2 Conjugate Gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6.3 BFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.7 Optimization Strategies and Meta-Algorithms\n",
    "* 8.7.1 Batch Normalization\n",
    "* 8.7.2 Coordinate Descent\n",
    "* 8.7.3 Polyak Averaging\n",
    "* 8.7.4 Supervised Pretraining\n",
    "* 8.7.5 Designing Models to Aid Optimization\n",
    "* 8.7.6 Continuation Methods and Curriculum Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.1 Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.2 Coordinate Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.3 Polyak Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.4 Supervised Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.5 Designing Models to Aid Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7.6 Continuation Methods and Curriculum Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1] DEEP LEARNING (Yoshua Bengio) : 8. Optimization for Training Deep Models - http://www.deeplearningbook.org/contents/optimization.html\n",
    "* [2] An overview of gradient descent optimization algorithms - http://sebastianruder.com/optimizing-gradient-descent/index.html\n",
    "* [3] Stochastic gradient methods\n",
    "for machine learning -  http://research.microsoft.com/en-us/um/cambridge/events/mls2013/downloads/stochastic_gradient.pdf\n",
    "* [4] (OXFORD, Machine Learning: 2014-2015\n",
    ")Deep Learning Lecture 6: Optimization - https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/lecture5.pdf\n",
    "* [5] 다크프로그래머 : Gradient, Jacobian 행렬, Hessian 행렬, Laplacian- http://darkpgmr.tistory.com/132\n",
    "* [6] 조금은 느리게 살자 : 테일러 급수(級數, Taylor series) - http://ghebook.blogspot.kr/2010/07/taylor-series.html\n",
    "* [7] 다크프로그래머 : 테일러 급수의 이해와 활용 (Taylor series) - http://darkpgmr.tistory.com/59\n",
    "* [8] Empirical Risk Minimization - http://demo.clab.cs.cmu.edu/fa2015-11763/slides/erm.pdf\n",
    "* [9] The Learning Problem and Regularization - http://www.mit.edu/~9.520/spring11/slides/class02.pdf\n",
    "* [10] Risk Minimization - http://hellbell.tistory.com/entry/Risk-Minimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
