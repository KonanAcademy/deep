{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 REGULARIZATION FOR DEEP LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 유주원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7.8 Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 충분히 overfit이 가능한 거대한 모델을 training 하려고 할 때, 시간이 지남에 따라 training error가 감소하는 것을 보게 될 것이다. 하지만 그와는 반대로 어느 순간부터 validataion error는 증가하게 되며 그럼 7.3에서 이를 보여주고 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/fig1.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 우리는 validation error가 가장 낮은 시점의 parameter를 리턴함으로써 더 나은 모델을 얻을 수가 있다.\n",
    "* validation error가 향상될 때마다 해당 시점에서의 model parameter를 저장한다. 그리고 training이 종료되면 저장된 파라미터를 리턴한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/fig2.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 이와 같은 전략을 early stoping이라고 부르며, deep learning에서 효율적이고 단순함 측면에서 많이 사용되고 있다.\n",
    "* early stopping을 통해 매우 효과적으로 hyperparameter를 선택할 수가 있다.\n",
    "* 아래 그림처럼 대부분의 hyparameter들은 u 모양의 performance curve를 가지는데, early stopping의 경우 training set이 가장 적합하게 될 수 있는 training step을 결정할 수가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/fig3.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* early stopping을 통해 hyperparameter를 결정하는데 있어 발생하는 비용 중 하나가 training 동안에 주기적으로 validation을 실행해야 한다는 것이다.\n",
    "* 위의 문제는 병렬 환경에서 training을 진행함으로써 해결할 수 있다. \n",
    "* 만약 병렬 환경이 없다면, 비용을 줄이기 위해 validation set을 줄이거나 validation 평가 주기를 늘리는 방법이 있고, 최적의 training time 보다 좀 덜 성능 좋은 training time을 선택하는 방법도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 또 하나의 비용이 발생하는데 바로 최적 파라미터를 복사하고 유지시키는 작업이다.\n",
    "* 이 비용은 무시해도 될 수준인데 그 이유는 최적 파라미터는 그렇게 자주 덮어써지지 않고, 또한 training 동안에는 결코 read가 되지 않기 때문에 전체 training 시간에는 거의 영향을 미치지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Early stopping은 training 절차에 어떤 변화도 끼치지 않기 때문에 동적인 학습에 있어서 어떠한 피해도 주지 않는다.\n",
    "* Early stopping은 단독으로 쓰이거나 다른 regularization 전략과 함께 쓰일 수가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 책에서는 early stopping을 위한 두 가지 방법이 제시되는데 첫 번째는 모델을 다시 초기화하고 모든 데이터들을 다시 retrain 하는 것이다. \n",
    "* 두 번째 training 과정에서 첫 번째 과정에서 결정된 early stopping의 step만큼 train을 진행한다.\n",
    "* 이 방법은 확신할 수 없는 몇 가지 세부 요소들을 담고 있다.\n",
    "* 예를 들어 동일한 수의 파라미터 업데이트가 retrain에도 적용될지의 여부를 알 수가 없다. 왜냐하면 두번째 train에서 training set은 더 커졌고 그에 따라 더 많은 파라미터 업데이트가 요구될 수도 있기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/fig4.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 두 번째 방법은 첫 번째 train에서 얻은 파라미터들을 보존시키기 위해 모든 데이터를 사용하는 방법이다. \n",
    "* 여기서는 몇 번째 step에서 멈추라는 가이드를 주지는 않는다. 대신에 validation set의 평균 loss function을 관찰할 수가 있고, training set의 loss 아래로 떨어지기 전까지 training을 계속 진행 할 수가 있다.\n",
    "* 이 전략은 모델 retraining 시에 높은 비용을 피할 수 있지만, 잘 동작하지는 않는다.\n",
    "* 예를 들어 valication set이 목표 값에 도달할 수 있는지에 대한 보장을 해주지 않는다. 그래서 이 전략은 종료를 보장해 주지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/fig5.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Early stopping은 training 절차의 계산 비용을 줄여 줄 수 있기 때문에 매우 유용하다.\n",
    "* 게다가 training 반복 횟수에 제한을 검으로써 추가적인 penelty term 없이도 regularization 효과를 볼 수가 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How early stopping acts as a regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 어떻게 early stopping이 L2 regularization과 동일한지 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/fig6.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* j(w*) 에 대한 근사 함수를 정의하고 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/fig7.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* wt 와 w*의 차이를 구함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/fig8.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* H를 eigenvector의 공간 내에서 다시 표현하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/fig9.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/fig10.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/fig11.png\" width = \"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Early stopping은 최적의 지점을 찾기 위해 validation set error를 계속 모니터링 한다. 이렇게 자동으로 regularization의 올바른 양을 결정할 수 있다는 측면에서 weight decay보다 강점이라고 할 수 있다. 반면에 weight decay는 다양한 hyperparameter 들과 함께 수많은 training 경험이 요구된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
